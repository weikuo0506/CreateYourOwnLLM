{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pretrain on unlabeled data",
   "id": "96029241f3323c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:29.631764Z",
     "start_time": "2025-06-08T09:24:27.159725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from gpt2 import load_model, complete_text, text_to_tensor\n",
    "\n",
    "start_context = \"Hello, my name is\"\n",
    "model = load_model()\n",
    "print(complete_text(start_context, model,10))"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is hauled manyrikesdeconder ZionJS partingachusetts Civic\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate Text without training",
   "id": "59d0d184b619cfd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:29.845756Z",
     "start_time": "2025-06-08T09:24:29.770805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2 import dataloader_v1\n",
    "\n",
    "with open(\"world_war_ii.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "dataloader = dataloader_v1(raw_text,batch_size=2, context_size=4,stride=1)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"shape of input: \",inputs.shape)\n",
    "print(\"first batch, input: \\n\", inputs,\"\\n targets: \\n\", targets)"
   ],
   "id": "4421717b10a6f375",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input:  torch.Size([2, 4])\n",
      "first batch, input: \n",
      " tensor([[10603,  1810,   314,   393],\n",
      "        [ 1810,   314,   393,   262]]) \n",
      " targets: \n",
      " tensor([[1810,  314,  393,  262],\n",
      "        [ 314,  393,  262, 3274]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:29.857256Z",
     "start_time": "2025-06-08T09:24:29.853986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2 import tensor_to_text,build_tokenizer\n",
    "tokenizer = build_tokenizer()\n",
    "for i in range(inputs.size(0)):\n",
    "    text = tensor_to_text(inputs[i].unsqueeze(0), tokenizer)\n",
    "    print(f\"Input {i}: {text}\")\n",
    "\n",
    "for i in range(targets.size(0)):\n",
    "    text = tensor_to_text(targets[i].unsqueeze(0), tokenizer)\n",
    "    print(f\"target {i}: {text}\")"
   ],
   "id": "ecd964b80608361d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 0: World War I or\n",
      "Input 1:  War I or the\n",
      "target 0:  War I or the\n",
      "target 1:  I or the First\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:29.926883Z",
     "start_time": "2025-06-08T09:24:29.872705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"shape of logits: \",logits.shape)\n",
    "print(\"shape of probas: \",probas.shape)"
   ],
   "id": "2a0917e20a6cdcf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of logits:  torch.Size([2, 4, 50257])\n",
      "shape of probas:  torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:29.939490Z",
     "start_time": "2025-06-08T09:24:29.936272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_token_ids = torch.argmax(probas, dim=-1) # Replace probas with logits yield same result\n",
    "print(\"shape of output_token_ids: \",output_token_ids.shape)\n",
    "print(\"output_token_ids: \\n\",output_token_ids)\n",
    "\n",
    "for i in range(output_token_ids.size(0)):\n",
    "    text = tensor_to_text(output_token_ids[i].unsqueeze(0), tokenizer)\n",
    "    print(f\"output {i}: {text}\")"
   ],
   "id": "215416f63d005e46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output_token_ids:  torch.Size([2, 4])\n",
      "output_token_ids: \n",
      " tensor([[38491,  2448, 36069, 24862],\n",
      "        [36397, 15489, 10460, 18747]])\n",
      "output 0:  constants Per Rebels myriad\n",
      "output 1:  Gathering bay 800array\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loss: Cross-Entropy and Perplexity",
   "id": "e550ca1ef5764591"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:29.953429Z",
     "start_time": "2025-06-08T09:24:29.950439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"shape of probas: \",probas.shape)\n",
    "print(\"shape of targets: \",targets.shape)\n",
    "print(targets)\n"
   ],
   "id": "adbeb698f6e1d36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of probas:  torch.Size([2, 4, 50257])\n",
      "shape of targets:  torch.Size([2, 4])\n",
      "tensor([[1810,  314,  393,  262],\n",
      "        [ 314,  393,  262, 3274]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:29.972513Z",
     "start_time": "2025-06-08T09:24:29.968663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size, seq_len = targets.shape\n",
    "target_probas = torch.empty(batch_size, seq_len)\n",
    "\n",
    "for text_idx in range(batch_size):\n",
    "    positions = torch.arange(seq_len)\n",
    "    #same as probas[0,[0,1,2,3],[2402,  257,  640,  612]], advanced indexing\n",
    "    target_probas[text_idx] = probas[text_idx, positions, targets[text_idx]]\n",
    "    #Note that even for the same token ID, the predicted probabilities can vary across positions or sequences because the model's output depends heavily on the surrounding context.\n",
    "    print(f\"Text {text_idx + 1} target_probas:\", target_probas[text_idx])\n"
   ],
   "id": "f21ae3e75ca8da82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 target_probas: tensor([9.9453e-06, 1.9406e-05, 1.4083e-05, 1.9301e-05])\n",
      "Text 2 target_probas: tensor([1.6926e-05, 2.1976e-05, 1.0548e-05, 1.9390e-05])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Cross Entropy Loss\n",
    "\n",
    "For a single classification sample, assume:\n",
    "\n",
    "- True label (one-hot):\n",
    "  $$\\mathbf{y} = (y_1, y_2, \\dots, y_C), \\quad y_i \\in \\{0, 1\\}$$\n",
    "\n",
    "- Predicted probabilities:\n",
    "  $$\\hat{\\mathbf{y}} = (\\hat{y}_1, \\hat{y}_2, \\dots, \\hat{y}_C), \\quad \\sum_{i=1}^C \\hat{y}_i = 1$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Cross Entropy Loss (General Form)\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{i=1}^C y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "If the true class is \\(k\\), the formula simplifies to:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\log(\\hat{y}_k)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Cross Entropy Over a Batch of \\(N\\) Samples\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{batch}} = - \\frac{1}{N} \\sum_{n=1}^N \\sum_{i=1}^C y_i^{(n)} \\log \\left( \\hat{y}_i^{(n)} \\right)\n",
    "$$\n"
   ],
   "id": "529a75dc72059a40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:29.992278Z",
     "start_time": "2025-06-08T09:24:29.989455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "neg_log_probas = torch.log(target_probas) * -1\n",
    "print(\"neg_log_probas: \",neg_log_probas)\n",
    "loss = torch.mean(neg_log_probas)\n",
    "print(\"loss: \",loss)"
   ],
   "id": "a7f711896f0272f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_log_probas:  tensor([[11.5184, 10.8499, 11.1706, 10.8554],\n",
      "        [10.9867, 10.7256, 11.4596, 10.8508]])\n",
      "loss:  tensor(11.0521)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:30.015331Z",
     "start_time": "2025-06-08T09:24:30.011368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"shape of inputs: \",logits.shape) #(batch_size, seq_len, vocab_size)\n",
    "print(\"shape of targets: \",targets.shape)\n",
    "print(\"targets: \\n\",targets) #(batch_size, seq_len)\n",
    "# inputs must be raw logits (unnormalized scores), NOT probabilities\n",
    "# inputs shape: (batch_size * seq_len, vocab_size)\n",
    "# targets shape: (batch_size * seq_len,), containing class indices\n",
    "loss = torch.nn.functional.cross_entropy(logits.view(-1,logits.size(-1)), targets.view(-1))\n",
    "print(\"loss: \",loss)"
   ],
   "id": "eec9532018efd4a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of inputs:  torch.Size([2, 4, 50257])\n",
      "shape of targets:  torch.Size([2, 4])\n",
      "targets: \n",
      " tensor([[1810,  314,  393,  262],\n",
      "        [ 314,  393,  262, 3274]])\n",
      "loss:  tensor(11.0521)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Perplexity and Cross Entropy Loss\n",
    "\n",
    "Given the average cross entropy loss \\(\\mathcal{L}\\) defined as:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\frac{1}{N} \\sum_{i=1}^N \\log P(w_i)\n",
    "$$\n",
    "\n",
    "The **perplexity** is computed by exponentiating the loss:\n",
    "\n",
    "$$\n",
    "\\mathrm{Perplexity} = e^{\\mathcal{L}}\n",
    "$$\n",
    "\n",
    "Perplexity can indeed be larger than the vocabulary size, though usually it’s not.\n"
   ],
   "id": "4a0efade7bf3a4fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:30.037960Z",
     "start_time": "2025-06-08T09:24:30.035408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "perplexity = torch.exp(loss)\n",
    "#Note perplexity is larger than vocab_size, which is expected, since the model is not trained yet.\n",
    "print(\"perplexity: \",perplexity)"
   ],
   "id": "7bd5f352b1a8ff22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity:  tensor(63076.7070)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Losses on the training and validation sets\n",
   "id": "43242757c26e2a3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:30.066057Z",
     "start_time": "2025-06-08T09:24:30.057813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If you didn't clean the empty lines, LLM may learn to add too many blanks.\n",
    "def clean_text_remove_empty_lines(text: str) -> str:\n",
    "    lines = text.splitlines()\n",
    "    non_empty_lines = [line.strip() for line in lines if line.strip() != \"\"]\n",
    "    return \"\\n\".join(non_empty_lines)\n",
    "\n",
    "with open(\"world_war_ii.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "cleaned_text = clean_text_remove_empty_lines(raw_text)\n",
    "\n",
    "print(cleaned_text[:200])\n",
    "tokens = tokenizer.encode(cleaned_text)\n",
    "print(\"Characters: \",len(cleaned_text))\n",
    "print(\"Tokens: \",len(tokens))"
   ],
   "id": "54ac217af9e00aa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World War I or the First World War (28 July 1914 – 11 November 1918), also known as the Great War, was a global conflict between two coalitions: the Allies (or Entente) and the Central Powers. Fightin\n",
      "Characters:  88775\n",
      "Tokens:  18134\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:30.090367Z",
     "start_time": "2025-06-08T09:24:30.078230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2 import GPT_CONFIG_124M\n",
    "\n",
    "# Split text data into training and validation sets\n",
    "train_ratio = 0.8\n",
    "split_idx = int(len(cleaned_text) * train_ratio)\n",
    "train_data, val_data = cleaned_text[:split_idx], cleaned_text[split_idx:]\n",
    "print(\"Train data: \", len(train_data))\n",
    "print(\"Val data: \", len(val_data))\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = dataloader_v1(\n",
    "    train_data, batch_size=2,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True, shuffle=True)\n",
    "val_loader = dataloader_v1(\n",
    "    val_data, batch_size=2,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False, shuffle=False)\n"
   ],
   "id": "89541052c1784c96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  71020\n",
      "Val data:  17755\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:30.105950Z",
     "start_time": "2025-06-08T09:24:30.102535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train dataloader: \", len(train_loader))\n",
    "train_first_batch = next(iter(train_loader))\n",
    "print(train_first_batch[0].shape, train_first_batch[1].shape)\n",
    "print(\"Val dataloader: \", len(val_loader))\n",
    "val_first_batch = next(iter(val_loader))\n",
    "print(val_first_batch[0].shape, val_first_batch[1].shape)\n"
   ],
   "id": "5e5c630757c48d16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:  7\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "Val dataloader:  2\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:30.127727Z",
     "start_time": "2025-06-08T09:24:30.124313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_batch(inputs, targets, model, device):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    logits = model(inputs)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), targets.flatten(0))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss_loader(loader, model, device, num_batches=None):\n",
    "    if len(loader) == 0:\n",
    "        return float('nan')\n",
    "\n",
    "    total_loss = 0.0\n",
    "    # num_batches no more than len(loader), default to len(loader)\n",
    "    num_batches = min(num_batches or len(loader), len(loader))\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = loss_batch(inputs, targets, model, device)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ],
   "id": "15723db4b3ce982b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:24:39.395690Z",
     "start_time": "2025-06-08T09:24:30.144117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MPS may have some issues when training, using cpu for play\n",
    "# device = (\n",
    "#     torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "#     else torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "#     else torch.device(\"cpu\")\n",
    "# )\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = loss_loader(train_loader, model, device)\n",
    "    val_loss = loss_loader(val_loader, model, device)\n",
    "print(\"Train loss: \", train_loss)\n",
    "print(\"Val loss: \", val_loss)"
   ],
   "id": "4e1fb5a7899e0d29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  11.002508980887276\n",
      "Val loss:  10.987592697143555\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "96731e56198e205c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:36:36.634182Z",
     "start_time": "2025-06-08T09:36:36.628615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, tokens_seen_track = [], [], []\n",
    "    tokens_seen, step = 0, 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tokens_seen += input_batch.numel()\n",
    "            step += 1\n",
    "\n",
    "            if step % eval_freq == 0:\n",
    "                train_loss = loss_loader(train_loader, model, device, eval_iter)\n",
    "                val_loss = loss_loader(val_loader, model, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                tokens_seen_track.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, tokens_seen_track\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = complete_text(start_context, model,20)\n",
    "        print(result)\n",
    "    model.train()\n"
   ],
   "id": "370c1fe6bc408a88",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:36:02.306696Z",
     "start_time": "2025-06-08T09:26:55.229465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2 import GPT2Model\n",
    "import time\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "# Initialize model and optimizer\n",
    "model = GPT2Model(GPT_CONFIG_124M).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"at the start of\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Report execution time\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f\"Training completed in {elapsed:.2f} minutes.\")\n"
   ],
   "id": "cb32329ab923e333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000005): Train loss 8.430, Val loss 8.680\n",
      "at the start of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000010): Train loss 7.085, Val loss 7.874\n",
      "at the start of the the, the, the, the, the, the, the, the, the, the, the, the, the, the the the the, the, the, the the the, the, the, the, the, the,\n",
      "Ep 3 (Step 000015): Train loss 6.544, Val loss 7.768\n",
      "Ep 3 (Step 000020): Train loss 6.333, Val loss 7.867\n",
      "at the start of the war, the war, and the war, the war, and the war, the war, the war, and the war, and the war, and the war, the war, the war, the war, the war, and the war\n",
      "Ep 4 (Step 000025): Train loss 6.149, Val loss 7.955\n",
      "at the start of the war, and French, and the war, and the war, and the war, and French, and the war, and the war, and the war, and French, and the war, and the war, which, and the war,\n",
      "Ep 5 (Step 000030): Train loss 5.999, Val loss 7.856\n",
      "Ep 5 (Step 000035): Train loss 6.005, Val loss 8.046\n",
      "at the start of the war, and, and, and, and the war, and, and the war, and the war, and the war, and the war.\n",
      "===\n",
      "===\n",
      "===\n",
      "===\n",
      " of the war, the war.\n",
      "===\n",
      "\n",
      "Ep 6 (Step 000040): Train loss 5.695, Val loss 7.746\n",
      "at the start of the war, and French, and the war. The. The, and the war, and French, and the German, and the war, the war, and the war. The German,000, the war. The. The, and the\n",
      "Ep 7 (Step 000045): Train loss 5.378, Val loss 7.734\n",
      "at the start of the war on the war.\n",
      "===\n",
      "==== of the war on the war.\n",
      "===\n",
      "==== of the war.\n",
      "==== of the war.\n",
      "==== British of the war on the war.\n",
      "==== German and the Battle of the war\n",
      "Ep 8 (Step 000050): Train loss 5.066, Val loss 7.661\n",
      "Ep 8 (Step 000055): Train loss 4.779, Val loss 7.621\n",
      "at the start of the war on the war, the war, the German Army, the war, the war, the war on the German, the war on the war on the war on the war, the war. The German Army to the war, the war,\n",
      "Ep 9 (Step 000060): Train loss 4.463, Val loss 7.625\n",
      "at the start of the Battle of the Battle of the war.\n",
      "The, the war.\n",
      "The by the war.\n",
      "==== German, the war on the war. The German forces.\n",
      "The Ottoman Empire, and the war.\n",
      "==== German and the war\n",
      "Ep 10 (Step 000065): Train loss 4.226, Val loss 7.587\n",
      "Ep 10 (Step 000070): Train loss 3.661, Val loss 7.597\n",
      "at the start of the war, and Austria-Hungary and the German Army, and the war.\n",
      "===\n",
      "The German forces to the war, the war, the German, and the war, the war.\n",
      "The German Army, and the war, and\n",
      "Training completed in 9.11 minutes.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T09:26:47.598343Z",
     "start_time": "2025-06-08T09:21:18.847313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs, tokens, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs, train_losses, label=\"Train loss\")\n",
    "    ax1.plot(epochs, val_losses, linestyle=\"--\", label=\"Val loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ],
   "id": "7d21c133b9acb67f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABM+klEQVR4nO3dB1yVZfsH8B8bQUBEZbj33itHWWnOnJUNM8u2lpZl5duwUrMsrSyz8Zb9e9XUhjPNreXKkeLem+lCQGQI5/+5rsNzOCAqInAGv+/ncwvnnIdz7ueA53ruebmYTCYTiIiIyC652roCREREdG0M1ERERHaMgZqIiMiOMVATERHZMQZqIiIiO8ZATUREZMcYqImIiOwYAzUREZEdY6AmIiKyYwzURA7m+PHjcHFxwY4dO2xdFSIqAgzURDYggfZ65d1337V1FYnITrjbugJExVFUVJTl+9mzZ+Odd97BgQMHLPeVLFnSRjUjInvDFjWRDYSEhFhKQECAtqKN2+XKlcOkSZNQoUIFeHl5oUmTJvjzzz+v+Vzp6ekYPHgw6tSpg5MnT+p98+fPR7NmzeDt7Y1q1arhvffew5UrVyw/I6/33//+F3379oWPjw9q1qyJBQsWWB6/cOECBgwYgLJly6JEiRL6+LRp065Zh19//RUNGzbUY4OCgtCpUydcunTJ8ri8Vt26dbU+Us+vvvoq28+fOnUK/fv3R6lSpVC6dGn07t1bu/gNjz/+OPr06YNPPvkEoaGh+hpDhw5FWlpaPt59Igcj2bOIyHamTZtmCggIsNyeNGmSyd/f3/Tzzz+b9u/fb3rttddMHh4epoMHD+rjx44dk4x3pu3bt5uSk5NNffv2NTVt2tQUGxurj//111/68z/++KPpyJEjpmXLlpmqVKlievfddy2vIT9foUIF08yZM02HDh0yDRs2zFSyZEnTuXPn9PGhQ4eamjRpYtqyZYu+3vLly00LFizItf6RkZEmd3d3rbccu3PnTtOUKVNMCQkJ+vj06dNNoaGhpt9++8109OhR/Vq6dGmtn0hNTTXVrVvXNHjwYP3ZvXv3mh555BFT7dq1TSkpKXrMoEGD9Jyee+450759+0wLFy40+fj4mL799ttC+70Q2QsGaiI7C9RhYWGmcePGZTumZcuWpiFDhmQL1H///bepY8eOpvbt25vi4uIsx8p9H3zwQbaf/9///qfB0iA//9Zbb1luJyYm6n1LlizR2z179jQ98cQTear/tm3b9GePHz+e6+PVq1fXCwJrY8aMMbVp08ZSNwnKGRkZlsclQJcoUcK0dOlSS6CuXLmy6cqVK5ZjHnjgAdODDz6YpzoSOTKOURPZkfj4eERGRqJdu3bZ7pfb4eHh2e57+OGHtXt81apV2uVskOPWr1+PcePGZeseT05ORlJSknZ1i0aNGlke9/X1hb+/P2JjY/X2888/j/vuuw///vsvOnfurN3Obdu2zbXOjRs3RseOHbXru0uXLnr8/fffj8DAQO3+PnLkCJ588kk8/fTTlp+Rbnjp8jfqe/jwYfj5+WV7Xqmv/Kyhfv36cHNzs9yWLvBdu3bl+b0lclQM1EQOqnv37pg+fTo2btyIu+++23J/YmKijkn369fvqp+RMWKDh4dHtsdk3DojI0O/79atG06cOIHFixdj+fLlGohlTFjGiHOS4CnHbNiwAcuWLcMXX3yBN998E//884/louC7775D69atr/o5o77NmzfHjBkzrnpuGSPPS32JnBkDNZEdkVZtWFiYtog7dOhguV9ut2rVKtux0upt0KABevXqhT/++MNyvEwikxnkNWrUuKW6SJAcNGiQlttvvx0jR47MNVAbQVNa/VJkBnvlypUxd+5cjBgxQs/n6NGjOjktN1Jfmfkuk+jk/IkoOwZqIjsjAXH06NGoXr26zviW2dayuUluLc4XX3xRu7XvvfdeLFmyBO3bt9dAKbcrVaqkXdCurq7avbx7926MHTs2T3WQ55BWrnQ3p6SkYNGiRTprOzfScl65cqV2eUuwldtnzpyxHC+t+2HDhmlXd9euXfX5tm7dqjPLJZBLAP/44491pvf777+v3fnSmv/999/x2muv6W2i4oyBmsjOSFC7ePEiXnnlFR0zrlevni6dkiVSuXnppZe0C1i6wmUZl4wTS2CVoPfRRx9pl7EsiXrqqafyXAdPT0+MGjVKl0jJ+Le0qGfNmpXrsdIK/uuvv/DZZ5/pGLu0pidOnKjd50JeV7rAJRjLRYiMh8t4ttRbyGPy86+//rp21yckJKB8+fLa3c4WNhHgIjPKbF0JIiIiyh03PCEiIrJjDNRERER2jIGaiIjIjjFQExER2TEGaiIiIjvGQE1ERGTHGKhv0vjx49GyZUvdl1g2d5A9kK3zCBt7FMt2i5KKT/IKy57JMTEx2Y6RdIQ9evTQNaTyPLK+1DoNoVizZo3u2iSpDmWXqR9//PGq+kyZMgVVqlTRrSFli8bNmzcXynl/+OGHuvuUsfbVGc8zIiICjz76qJ6PrB2Wtb6yMYdBVjLKRiCyx7Q8LqkcDx06lO05zp8/rxt4yPpfSdkoe1zLFpnWdu7cqeuS5VwqVqyICRMmXFWXX375Rdc+yzFSD9nKs6DIBilvv/02qlatquchG6uMGTNGz8/Rz1XWY/fs2VN3Q5O/13nz5mV73J7OKy91ye+5SvpPWZcuryvr1uWYxx57TPeRd7Zzzem5557TY2RdvyOea65snRXE0XTp0kWzHe3evdu0Y8cOU/fu3U2VKlXS7EMGScVXsWJF08qVK01bt2413Xbbbaa2bdtaHpcMQA0aNDB16tRJUxUuXrzYVKZMGdOoUaMsx0g6QEnjN2LECE3798UXX5jc3NxMf/75p+WYWbNmmTw9PU0//PCDac+ePaann37aVKpUKVNMTEyBnvPmzZs1TWKjRo1Mw4cPd8rzPH/+vGZnevzxx03//POP1ksyNx0+fNhyzIcffqhZrubNm2cKDw839erVy1S1alXT5cuXLcd07drV1LhxY9OmTZs0u1WNGjVMDz/8sOXxixcvmoKDg00DBgzQvyFJZSlZor755hvLMevXr9f3YMKECfqeSJYrSXO5a9euAjlXycwVFBRkWrRokWbi+uWXXzTF5eeff+7w5yp/Y2+++abp999/14xec+fOzfa4PZ1XXuqS33OVbGry/2727NmaKnXjxo2mVq1amZo3b57tOZzhXK3J43I+koHu008/dchzzQ0D9S2SHMDyh7N27VrLfxD5xcmHn0Hy58ox8p/F+KNzdXU1RUdHW46ZOnWq5ts18u9KDuL69etney1J6ScXCgb5jyd5gw3p6en6Bzp+/PgCOz/JKVyzZk3NR9yhQwdLoHa283z99dc1XeS1SArGkJAQ08cff2y5T94DLy8v/Q8t5D+unL/kcDZI2kgXFxdTRESE3v7qq69MgYGBlvM3XlvSPBr69+9v6tGjR7bXb926tenZZ58tkHOV55bcz9b69eunH1DOdK45P9Dt6bzyUpdbOddrXXDLcSdOnHDKcz19+rSpfPnyGmTlots6UDvquRrY9X2LZKtHUbp0af26bds27XaS7g6DdJPIvsuS5UjIV+kyCQ4Othwj2z7K9ot79uyxHGP9HMYxxnOkpqbqa1kfI3s6y23jmIIgXdvSdZ2zLs52nrJFZ4sWLfDAAw9oF33Tpk0145Ph2LFjiI6OzlYP2btauuGtz1e61OR5DHK81Ff2vzaOueOOO3SLTuvzleET2fs6L+/JrZJ0lbI398GDB/W27AO+bt06y5afznSu1uzpvPJSl8L4rJIuYTk/ZzvXjIwMDBw4UIfWZH/6nBz9XBmob/GPQ8ZsJWOQZDES8kuSX7Txn8EgwUoeM46xDl7G48Zj1ztGgtzly5dx9uxZHWvM7RjjOW6V7O0s+YhlXD4nZzpPIdmdpk6dqvtpL126VDNTyZ7b//d//5etvterh3yVIG/N3d1dL+IK4j0pqPN944038NBDD+mFlewDLhcl8ndsZLdypnO1Zk/nlZe6FCSZTyJj1pLD3Ng/3ZnO9aOPPtK6y//Z3Dj6uTIpxy22NiUjkbRGnM2pU6cwfPhwzTNsncPYWclFl1xtf/DBB3pbgpf8br/++mtN8+hM5syZo5m4Zs6cqa0PycwlgVom6jjbuZJ5Yln//v11kpNcjDqbbdu24fPPP9dGhfQYOCO2qPPphRde0AxFq1evzpaGLyQkRLtr4+Lish0vs6HlMeOYnLOjjds3OkauhmUmYZkyZeDm5pbrMcZz3Oofv2RuktnYcuUpZe3atZg8ebJ+L1eIznCeBpmhKVmqrEmaRpm1bl3f69VDvsp7Zk1muMts04J4TwrqfKV70GhVy9CEdBm+/PLLlp4TZzpXa/Z0XnmpS0EGaUkbKhfd1tnInOVc//77bz0PGXYzPqvkfCX7nKwUcYZzZaC+SXJVKkF67ty5WLVqlS5xsSY5fKU7UcYADTLGIR/4bdq00dvyddeuXdn+cIz/REawkGOsn8M4xngO6XaW17I+RlqFcts45lZIikGpo7S2jCItTukeNb53hvM0yPBFzmV2MoYrKRuF/J7lP5p1PaR7Xsa3rM9XLlzkIscgfyNSXxmjMo6RpSbyAWp9vrVr10ZgYGCe3pNblZSUpGNz1uRiSOrpbOdqzZ7OKy91KaggLUuDVqxYocsOrTnLuQ4cOFCXVVl/VknvkFyQyjCWU5xrvqehFVPPP/+8Tr1fs2aNKSoqylKSkpKyLVuSJVurVq3SZUtt2rTRknPZUufOnXWJlyxFKlu2bK7LlkaOHKmzqadMmZLrsiWZTfjjjz/qrMZnnnlGly1Zz7IuSNazvp3tPGVGrLu7uy5dOnTokGnGjBlar+nTp2dbdiGvO3/+fNPOnTtNvXv3znVpT9OmTXWJ17p163TGvPUSEJkBKktABg4cqLNT5dzkdXIuAZG6fPLJJ/qejB49ukCXZw0aNEhnxxrLs2RJiyybkxn4jn6uskpBlgJKkY+3SZMm6ffGTGd7Oq+81CW/55qamqrLgipUqKD/96w/q6xnNTvDueYm56xvRzrX3DBQ3yT5I8mtyNpqg/xChgwZolP95Rfdt29f/Q9i7fjx46Zu3brpOj35kHzllVdMaWlp2Y5ZvXq1qUmTJrqGuFq1atlewyDrjiVYyjGyjEnWCBaWnIHa2c5z4cKFemEhFwV16tQxffvtt9kel6UXb7/9tv5nlmM6duxoOnDgQLZjzp07p//5ZV2yLEN74okn9EPGmqytlKVg8hwSMOU/dk5z5swx1apVS89Xlq/98ccfBXae8fHx+nuU99Pb21vfc1mjav0B7qjnKn9Luf3/lIsTezuvvNQlv+cqF2DX+qySn3Omc81roHaUc82Ni/yT//Y4ERERFSaOURMREdkxBmoiIiI7xkBNRERkxxioiYiI7BgDNRERkR1joCYiIrJjDNQ2lpKSgnfffVe/Ojueq3MqLudaXM5T8FztC9dR25hsLydp0CQFnfU+vM6I5+qcisu5FpfzFDxX+8IWNRERkR1joCYiIrJjDp2PWtKUbd++XVMu5swG5CgSEhL0a0REhHbBODOeq3MqLudaXM5T8FwLn2TukvSXTZs21dSc1+PQY9RbtmxBq1atbF0NIiKifNm8eTNatmzpvC1qaUkbJxoaGmrr6hAREeVJVFSUNjSNOOa0gdro7pYgXaFCBVtXh4iI6KbkZdjWMQd2iYiIigkGaiIiIjvGQE1ERGTHGKiJiIjsGAN1To67Wo2IiJwQA7W1ixHA952B2H22rgkREZFioLa2dBRwejPwQxfgxAZb14aIiIiBOpt7PwMqtgaSLwI/9QH2LbJ1jYiIqJhjoLbmUxp4bD5QuzuQngLMGQhs/cHWtSIiomKMgTonjxJA//8BzR4DTBnAopeB1eM5yYyIiGyCgTo3bu5Az8nAHa+Zb+9bCKQl2bpWRERUDDn0Xt+FysUFuPtNILAKUP0uwNPX1jUiIqJiiC1qKylX0pGclp79zqYDAP+wrNu7fwcuXyjyuhERUfHEQJ1p1+mLuHfyOnz05/5rH7T7N+DXJ4AfupnXXBMRERUyBupM55NScSg2ET9uOI7Nx87nflDZOoBfKHBmX+bGKNcJ6kRERAWAgTpTh1pl8WCLijq5+7Vfw3E5NUcXuAiuDzy5DChTC4g/bd4Y5eQ/tqguEREVEwzUVt68ty5CA7xx/FwSPll2IPeDSlUCBi8FKrQEkuOAn3oB+xcXdVWJiKiYYKC24u/tgQ/6NdTvf1h/DFuOn7/OxigLgFpdgSvJwOwBQMzeoq0sEREVCwzUOdxVuxz6t6iQ2QW+M/cucOHpAzw4A2j6KND2RSC4XlFXlYiIigEG6ly82aMeQvy9cezsJUy8Vhe4sTFKry+BTu9l3ZeSCGRcI7gTERHdJAbqXASU8MD4zC7w79cfw9ZrdYEbG6NIEWnJwMz+wC+DzN8TERHdIgbqa7irTjnc39zcBT7y151Xb4SSm6gdwOkt5i1Hp/cDLscVRVWJiMiJMVBfx9v31kOwv9eNu8ANlW4DHv0d8PIHTqwHpnUH4iOLoqpEROSkGKjz2AX+33XHsO3EdbrADVVvB55YDJQMAWL3mDdGOZOHIE9ERGRvgTo9PR1vv/02qlatihIlSqB69eoYM2YMTHaUUvLuOsG4r1lmF/gveewCD2lo3hglqAZw8ZR5Y5RTW4qiukRE5GRsGqg/+ugjTJ06FV9++SX27duntydMmIAvvvgC9uSdzC7wo2cvYdLyg3n7ocDKwOBlQPnm5lzWXn6FXU0iInJCNk1zuWHDBvTu3Rs9evTQ21WqVMHPP/+MzZs3w54E+Ji7wAf/uBX//fsoutQPQfPKgTf+Qd8gYNBC4PwxoFydoqgqFXeyNFCGWiK2ARFbgYh/Ac+SQL1eQP1+gF+wrWtIRI7Uom7bti1WrlyJgwfNrdTw8HCsW7cO3bp1g72RLvB+zcojQ2eBh+etC1xIHuuQBlm3j/0F/D3R3MomulUZGVnf710AfFgJmNoGWPACsO1HIHoncHID8OcbwPG/s47l3x+Rw7Bpi/qNN95AfHw86tSpAzc3Nx2zHjduHAYMGJDr8SkpKVoMCQkJRVhbYPS99bHu0FkcPXMJny4/iFHd697cEyTEALMGACnxQHwU0O0jwNWtsKpLziYlAYjckdlS3gac3gbcNQpo9pj5cf/yQGoi4OELlG+WWZqb/9b2LwJqdcl6rvWfAQeXAfX7mlvbfiE2Oy0isuNAPWfOHMyYMQMzZ85E/fr1sWPHDrz00ksICwvDoEGDrjp+/PjxeO89q13AbNAF/kHfhnjqp634TrrAG4SgWaU8dIEbpNvx7reAJa8DW74DLsUCfb8FPLwLs9rFi2w0kxhjLgnR5nLlMtBueNYx6ycDZw+aA1tAecA/DPCvYP7e3uYSSN7zNR+Yu7Bj90lTOPvjp7dmBWqZxPj8RqBs7asvAG97Lvvt3b9ntbaXvAZUbgfU7wPUlaDN7nEie+JisuEU64oVK2qreujQoZb7xo4di+nTp2P//v03bFFHRESgXr16OHXqFCpUqFBk9R4xewd+3x6B6mV98cew2+HtcZOtYvmQnPsskJ4KVLkdeGgG4B1QWNV1DqmXzEHXCMByu9nArMd/fRI4vMKc0Swnd2/gzeisHeR+vDd7N7A1+T2MPGreHlbI5jWXL2QG9QrmoF7QwVz+C8rqAG0lbzWnUW2eeaGadB6YUDXrWLmgqNAcKN/C3FoOa2IeXrlZF08De+cDe+aaN+kxuLgCNTsDD8/Ker+IqMCdPn1aY2Be4pdNW9RJSUlwdc0+TC5d4BnW425WvLy8tBik29wW3ulZD38fPosj0gW+4iBGdbvJLvAG/QCfIHM3uAQM2RhlwC/mIFAcu3ONlq8MCdQxTyxUf7wKHF1jDs7ymDU3L3NCFCOYSBYzI0jLY9IqlLXsfpklPQ1w9zQ/3vpZoOod5mAlG9LER5hL8kXzzxpBWvzzzdVB3SvA/LsqVRF4eDZg/A1Li9fFzdwyv17wlAlfMlfBmOwlwVl6VwxVO2QFasnUJnvJl6lpDswF1UUtFx1thppL3MmsoC0XC1J36yC9cw5Q/W7At0zBvDYR3RSbBuqePXvqmHSlSpW063v79u2YNGkSBg8eDHtWysdTu8Cfli7wv46ia/0QNL2ZLnBRrYN5Y5QZ9wMxu80zw41AfWgFcHS1+cM0oKI5IMjXEoGO08qRVmLSOSAxNntmsTUfAsfXmQOkBOe0S1mPuXkCb8VmnWNCFHDuUNbjHj5AyeCs4HslJWvYoONo87CCPH6j96luT3PJSRKqSJ2tVWoDuHuZ6yvd0CkXzeXMReDy+awgLRaPzArq0jKX1q/8TiVwV7wNaPJw5oEu5v3g5cLA4OoOBNc3t5SrtMteh/YvoVBJjnXJACflwglzT49BLj5+f9rc0paLGxnTrtPTvKKBiJy/61smg8mGJ3PnzkVsbKyOTT/88MN455134OmZ2fopoK6DwvDSrO2YtyMSNcqVxKIX2998F7i4cByY9WhmizrUfN+yt4ANuawll0lCErwfnA6UrWW+7+wh4NIZ8/1+Ydlbg4VF/mSsA6HMNo78NyuYaQs1EkhPMbdQ34rJOn72o+buZGuy5aoRgB+ZY04hKqR1J13c2jIONh9n6wsV6QHQ8zxtbsVb9wBMvx849c/VrX8jGL60K+v2/KFA2uWsLuzQRoBHCdidExuBpaOAyO1Z90mvgRG05YJHWv1EdFNuJn7ZNFDfKlsH6rikVHSa9BfOJqbg+Tur4/Wu+VwrbfwKjCB0aLm5y1fGLeNOmYOCddfoiP25B3Vp9Uiw1hZ4Zmv8tiFAybJZXa55nWV+5iBw7nBWt7B1EJZx0zdOXD/4GiQAD/3H3MoV2pV9xtzSNFrG+RljtWfJ8Zld6qez3jfpHej+sbl17oikx2fvPHP3eFR41v1yYWU9m5yInGuM2tGZu8Ab4Jn/bcM3a4/oRihNKpa6+SfK2UqseY+55JzNLEFSgrcEP4OnHxBY1fyYdFlqcDid9XirZ7K+XzEa+Pd/WV3pEsylO1mCiHRDD5yX1ZW7agywb8G163zpbNYFQM0u5gsE7ebN7O6VyVd+oVnjwoZqd8LpefubizNtclO6KtD+ZXM5d8QctA+vBKrdlXXMqnHmnhXtHu+RdXFGRLeELeoCMHzWdszfEYma5UpiYX67wG+VTMCTVre0vmVykHyV0vXDrOA7Z5D5A/ZaXj2cFXxlLPngn+aAqyVHEJbvuQacDPIxMrmJeShHuHoAYU3NPQgy/h5UHegxMev4JW+Yh2zkb0gel94g+Sq35UK0w2tZx26WpYxnM491M3e9G8fKDHyZVGjQmf8XgRKlzZPffKQEXX3BSGRj7PouYhcupeKeT81d4EPurI7X8tsFXhTjqxrIpTs9s8g4qRF8a3UFvEraupbkqGS+xJ7M7nHJHGctpBHwnNXs+c8bZwX1nCSZzYvbsm5/1fbq5zNIT84rsr4803cdzbPpc5KZ+nJxOWRD1n3hs8wXAEZAlwly+rWMfc4XIKfCru8iFujriXF9G+DZ/23D15ld4I3z0wVe2KT1Ua6uuRAVNFlC1mGkucgch9i9QMYVwJRhnghorcPrwOU4wJRuPkbmT0iR2945/u806AvE35b5XJnHabkClMhxrEzMk1a8zN43iry+zNRPznERuuV74PQ18gpIK/y1o1m3N35lHl6yBHXr4B5kHxMdyWkxUBcQCc69GodhQXik7gUuXeBe7uwapmJKViUYKxNy0+SRvD/XHSPzfmz3CVcPCcn6emk5pyVlf0wmwUmWO3ks6SxwSQL7WfNcD/ccLWrdGOYaQV2OfSs6+/p/uUiR+R8yUdIoclsulu94NetYWdkgkw8lcYqsdtCfyfxenjfHPhNUPDFQF6B3e9XHhiNncTAmEZNXHsLILnbaBU5UXEigk+VjuS0hsw6YBhkJlCEiKdaaDgAqtjK30I3Art+fu/q5ZWtWWaaXGwnC1q8rE/COrMz9WBm3f/tcVrCWFR4nN2UGfeMCQIK7r/mYe8Zktep3zASidpq3nJUeBR3hNGV97TI+aw+C7dOBkxszd6e1Osb4KqsVjJ0T5ViZB2CMmLp5mIcJtD4+5lUmxsY4MXvNwxtGHY0LEb0Ysao33RADdQEq7euJsX0a4rnp0gVuTofZqIIddoETUe4k0Bmz9q01f/zaPyMb71jr9G7mZj5JQGqSeVMf2Q9Avs/ZPS4t+nL1zclU9PhLWS1/2frWOpDF7s++3WtOnd63WuK5zNwLcC33vC/LE8zfn9gA7Jhx7WM7j836XpLCXO95Zd95I1DvnAWs//zaxz63PiuzoEwY3PLf7EHf6JHw8DFvxiPvlYjZY17XbwyV6NeMrNsN7s9avnpqs3m5q+U4+ZqRdVt2KZQhG3F0rfl9uNbz3vEaULElbIGBuoB1bRCCno3DsFC6wH/ZiQUvtmMXOJEzy7k2vnLbvP/svZ9efZ8EEkkkIxM9rd31H/MFgwb0RHPg18B+yRxQrNW517xsU1rlGrxdsn+VXQANkoildLVrH2u9z0G93ubJfsbjGWlWFyNJ2ZfkyUQ/mTNg/bick7EbofWEPRn/P3N1fgeLZrKvf2agPrDEvHz0Wiq0zArUcmHzV47hkGzvU/esQH3+KLBz9nXqcHWiqKLCWd+F4LzMAp+0FucupeKFu2rg1S61bV0lIiL7ICFHArZ1j4FsXRt3IkdQt+phaPVs1tJR2Xt+1y+Zy/TcMpf2Gcv23MxzGozgK3vqy86JlsflYsRqmV/jh8xLB0X0bvPWzdd6XtmNT3YYLCBcnmUHluyKwvMz/oWbqwvmDWmHhhWYHYuIiG4+fnEkv5B0axiKexuFIj3DhFd/CUfqldwzghEREV0PA3Uheq9XfQT5euJATAK+WGWVBYqIiCiPGKgLUVBJL4zpY57V+NWaI9gdYZXWkIiIKA8YqAtZ94ah6NGQXeBERJQ/DNRF4P3e9XWN9f7oBHy5+rCtq0NERA6EgbqousB7Z3aBrz7MLnAiIsozBuoi0qNRKLo3DMEVdoETEdFNYKAuQu/3bmDpAp/CLnAiIsoDBuoiVKakl45XCwnUeyLZBU5ERNfHQF3EZAZ4twZGF/hOdoETEdF1MVAXMRcXF+0CD/TxwL6oeHy1hl3gRER0bQzUNlDWT7rAzbPAv1x1GHsj421dJSIislMM1DYi+4B3rZ81CzwtnV3gRERkZ4G6SpUq2hWcswwdOhTOTs5Tthct5eOBvVHx+GIl9wInIiI7C9RbtmxBVFSUpSxfvlzvf+CBB1BcusAlcYeYvOownv5pK06dT7J1tYiIyI7YNFCXLVsWISEhlrJo0SJUr14dHTp0QHHRq3EYhnWsCXdXFyzfG4N7Pl2LL1cdQsqVdFtXjYiI7IDdjFGnpqZi+vTpGDx4sHYL5yYlJQXx8fGWkpCQAEcn5zrinlpYPPx2tK5aGslpGfhk2UF0/exv/HXwjK2rR0RENmY3gXrevHmIi4vD448/fs1jxo8fj4CAAEupV68enEWtYD/MeuY2fP5QE+0SP3b2Eh77YTOGzNiGqIuXbV09IiKyEReTyWSCHejSpQs8PT2xcOHCax4jLWophoiICA3Wp06dQoUKFeAs4pPT8Onyg/i/DceRYQJ8PN0wvGNNPNGuKjzd7ebaioiI8un06dOoWLFinuKXXXzqnzhxAitWrMBTTz113eO8vLzg7+9vKX5+fnBG/t4eGN2zPha9eDuaVw5EUmo6xi/Zj+6T/8bGI+dsXT0iIipCdhGop02bhnLlyqFHjx62ropdqRfmj1+ebYOP72+EIF9PHI5NxMPfbcLwWdsRG59s6+oREVFxCNQZGRkaqAcNGgR3d3dbV8fuuLq64IEWFbHqlTvx6G2VIPPs5u+IxN0T1+L7dcdwhRulEBE5NZsHaunyPnnypM72pmsL8PHA2D4NsWBoezSuWAqJKVcwZtFe3PvFOmw9ft7W1SMiImcN1J07d4bMZ6tVq5atq+IQGlYIwNzn2+KDvg11VzPJbX3/1xvxypxwnE3MmmhHRETOweaBmvLXHf5I60raHf5gi4p632//nsbdn6zB/zYeR7pMFSciIqfAQO3ASvt64qP7G+H3IW1RP8wf8clX8Pb8PegzZT12nIqzdfWIiKgAMFA7gWaVArHghfa6b7iftzt2RVxE36/WY9Tvu3DhUqqtq0dERLeAgdpJuLm6YFDbKtod3q9Zecg2Nj9vPom7J67BrM0nkcHucCIih8RA7WRk+9FJ/ZtgzrNtUDvYDxeS0vDG77tw39cbsDvioq2rR0REN4mB2km1qloai4a1x1s96sLX0w3bT8ah15frMHr+bly8nGbr6hERUR4xUDsxDzdXPHV7Nax69U70bBym+4b/38YT6DhxDX7bdlqXxRERkX1joC4Ggv298cXDTTHjqdaoXtYXZxNT8cov4ej/zUbtDmfAJiKyX9yzsxhpV6MMlgy/Q7cenbzyELYcv6A7mwX7e6FlldKWUjvETyenERGR7TFQFzOSJvP5O6ujd5MwjFu8D8v2RCMmPgWLdkZpEbLES7J2GYG7UYUAeHu42brqRETFUr4CteTPdHFxseTQ3Lx5M2bOnKm5oZ955pmCriMVgrBSJTDlkWa4nJqO8NNx2HLsPLacuIB/T1xAQvIVrDlwRovwdHPVYN2yqgTuQDSvXBoBJTxsfQpERMVCvgL1I488ogF54MCBiI6Oxj333IP69etjxowZevudd94p+JpSoSjh6YbbqgVpEZKNS/YP33L8vJbNxy7oHuJbT1zQMhXQDF6y9Eta2y2qBOoM89CAErY+FSIip+RiysdMosDAQGzatAm1a9fG5MmTMXv2bKxfvx7Lli3Dc889h6NHj6IonD59GhUrVtQWvtG6p4Ilfx4nziVZAvfW4xdw9Oylq44rX6qEBmwN3FVKo0a5ktrrQkREtxa/8tWiTktLg5eXlyVNZa9evfT7OnXqICrKPM5JzkGCbZUyvlokL7Y4k5CiqTVlMpoE7z2RFxERdxlzt0doEYE+HtpF3qpqIFpUKY0GYQE6Pk5ERDcnX4Faurm//vpr9OjRA8uXL8eYMWP0/sjISAQFmbtQybl3P+vWMFSLkNzY209K0L6gY93bT13QHdFW7IvRIrw9XNGkYiltbUvgblY5ECW9OJeRiOhG8vVJ+dFHH6Fv3774+OOPMWjQIDRu3FjvX7BgAVq1apWfpyQHJgH39ppltYjUKxnayjZ3l1/Q1rcE7k1Hz2sRsvpLuscbVSiFxhUC0LBCKdQN9YOXO2eXExHd8hi1SE9PR3x8vI5XG44fPw4fHx+UK1cORYFj1I5BEoIcPZuoE9OMse7TFy5fdZyHmwvqhPjrDHNzKYWa5UrC3Y1d5kTkXAp9jPry5cs6ycgI0idOnMDcuXNRt25ddOnSJX+1Jqfl6uqCGuX8tDzSupLeFxufjPDTF7HrdJx+3Xk6TlvdkqJTyox/YOkyrx9mDtyNK5TSr1WCfPU5iYiKg3wF6t69e6Nfv346wzsuLg6tW7eGh4cHzp49i0mTJuH5558v+JqSUynn74176kkJ1tty4Set7J2ZQVvWdu+OiNfx720nLmgxyIYsDcsHWHWbB+isc84yJyJnlK9A/e+//+LTTz/V73/99VcEBwdj+/bt+O2333QNNQM13SwJshVL+2jp0SjUqsv8kgZuI4DviYzXDVk2HDmnxRDk66mt7YaZwVuCuEx6IyIqloE6KSkJfn5++r2snZbWtaurK2677TbtBicquC7zklr6NTOP4aSlZ+BQTGJmq9scvA9EJ+DcpVSsPnBGiyE0wNsy1i3d5tIKD/DhjmpEVAwCdY0aNTBv3jyd+b106VK8/PLLen9sbCz8/f0Luo5E2VJ31gvz1/JQ5gKD5LR07IuKz2x1m4P34TOJiLqYrGXpHvMSMVElyEeTjtQK9kPNYPlaElXL+HK2ORE5V6CW7m3ZRlQC9N133402bdpYWtdNmzYt6DoSXZckDGlaKVCLQca290SYA7eMd8sENdlh7XhmsQ7ekilMAnjNcubAbQ7gfhrAuUkLETns8izZ01t2IZM11NLtbSTnkBa17FCWVxEREXj99dexZMkS7VKX1vq0adPQokWLG/4sl2fRzYhLStUJagdiEnBISmwiDsYk6Jh3btwlgJfx1eAtM9blqwRwmXXOAE5Edr08S4SEhGiRFxPyQje72cmFCxfQrl073HXXXRqoy5Yti0OHDmVbm01UUEr5eKJ9zTJaDHKdKmk+JWBLkfHvg7EJOByTiISUKzgcm6gFiM4WwKW1LUFbxs/lqwRxCerSNU9EVJDyFagzMjIwduxYTJw4EYmJ8iEGnVz2yiuv4M0337S0sPOyw5lcUUgL2lC1atX8VIko37PNQwK8tdxRy7yzmhHAo+OTcTAmUVvf5kBuDtrSrS6tcSk5N2yRAC5d5zWtAnjlIAZwIiriQC3B+Pvvv8eHH36oLWKxbt06vPvuu0hOTsa4cePy9Dyy5ahskPLAAw9g7dq1KF++PIYMGYKnn3461+NTUlK0GBISEvJTfaI8BXBJ3SmlQ44ALhPULK1vCeDS6o5JwKXUdA3mUnIG8GplSqKkt7v+fIYJkPEm8/cmyOCT3pf5vQmZx1gek3syv+r9xs9e59gM81e5r0JgCfRoGIqejcO01U9ExWCMOiwsTJNyGFmzDPPnz9dAK+POeeHt7a1fR4wYocF6y5YtGD58uD637CGek1wIvPfee1fdzzFqsjX5byQZxLSlndn6NsbBk1LTYS9kuVqvxmG6Vp05xIkcY4w6X4FaAuzOnTtRq1atbPcfOHAATZo00S1G88LT01MnjW3YsMFy37BhwzRgb9y48YYtarkgqFevHgM12S1p2UoAl+ViKWnp2lJ3dXGB7KEmI0TynWyopvcZXzNb9LJLatZXZP/ZzONv9LPy31t2dVsQHqkbxKRL81uPAVpWKa2t7O4NQhBUkpvDEDnVZDKZ6f3ll19i8uTJ2e6X+xo1apTn5wkNDdVAa032C5cdznIjObCNPNhCkoIQ2fumLcaOa7ZSrWxJzSV+NjEFS3ZFadCWrGabj53X8u6CPWhfo4wG7c71g+HvzU1hiOxJvgL1hAkTNBf1ihUrLGuopQUsVwaLFy/O8/PI+La0wq0dPHgQlStXzk+1iOg6ypT0wsA2VbRExl3Gop2RWBgepWvM1x48o8Vzrivuql0WvRqXx911yqGEJzeCIXLYddSRkZGYMmUK9u/fb2kJP/PMMzob/Ntvv83Tc0gXd9u2bXXcuX///roOWyaSyc8PGDDghj/PddREt+7omUQs2mluaZuXopn5erpp0hRpaUuuca4dJ3KgMeprCQ8PR7NmzTRXdV4tWrQIo0aN0vXTsjRLJpZda9Z3TgzURAVHPgr2RydowF4YHpktZ3hACQ90axCiE9FaVwvS3dyIqJgE6lvBQE1UOORjYfupOA3Y0to+k5A1iVOykslyr15NwtC0YimmFyWy153JiMh5SfBtVilQy1s96uGfY+c0aC/eFa1B+8cNx7XIGm3pGu/ZKAx1Q/0YtIkKAQM1EV2XdHO3rV5Gy3u9GmDd4TM6CW3ZnmjtHp+65oiW6mV9dRJaz8ahOtOciGwQqCXv9PXExcXdan2IyI7JhLK76wRruZyajtUHYrFgRyRWHYjFkTOX8OmKg1oalPfX8WxpbXNjFaIiDNQBAQE3fPyxxx67xSoRkSOQpVvdG4ZqSUhOw7I9MVi4MxJ/HzqrWcqkjF+yH62rlkafJuXRrUEoAny4RpvoZhXoZLKixslkRPbn/KVULJaNVXZEYvPx85b7Pd1ccWftsujT1LxGW/KIExVXpzmZjIhspbSvJx69rbKW0xeSdDx7/o4IXfq1bG+MFj8vd3RtEILeTcqjTXUu9yK6HraoiahI7I+Ox7ztkViwIwKRF5Mt95fz89Kx7N5NwtCwfABnjlOxcNpW66iLGgM1kWMmKtl64gLm7YjQLvK4pDTLY9XK+qJ34/IatJmSk5zZaQZqInIEqVcydI9x6RpfvjcGKVcyLI81rlgKfZqE4d5GYbrJCpEzYaAmIoeTmHIFS3dHa0t7/eGzyMzIqePX7WqU0aDduX4ISnpxag05Pk4mIyKHIwH4vuYVtMjuZ5Lda96OSISfisNfB89o8fbYhU51g3W51x21mCiEige2qInIrh07e0mXekn3+NGzlyz3l/Lx0DXcErRbVA7U3N9EjoJd30TkdOSjSnJny8xx2VjFOlFI+VIlNEmITEKrE+Jv03oS5QUDNRE5tfQMEzYeOafj2X/ujtbxbUOdED8N2pIopGJpH5vWk+haGKiJqNhITkvHyn2x2jUue4+npWd9pDWvHKh7jvdoFIoyJTlznOwHAzURFUsXk9KweLd5+9JNx87B+HQzZwAL0p3QutQPhp839xwn22KgJqJiLyY+WXNoSwk/fdFyv8wU71innLa07+Ke42QjDNRERFaOy8zxcPPMcUnHaZA9x2Vttoxpt6seBHc3LveiosFATUSUC/m42xsVr0F7UXgUIuIuWx4rU9JTl3vJzPFmlQK55zgVKgZqIqI87Dm+7eQFHc/+Y1eUpufMudxLusdlFjmDNhU0BmoiopuQlp6h25ZKS1u2Mb2Umm55rFZwSQ3YvRqXR6UgLveigsFATUR0C8u9Vu3PXO61/wxS07MShTSpWEqD9r2NQ1HOz9um9STHxkBNRFQALl5Ow9I90Tpz3DpRiOxW2kaWezUujy4NQhBQgsu9yEkD9bvvvov33nsv2321a9fG/v378/TzDNREVFRiE5KxeGcU5odHYvvJOMv9nm6uuLN2WR3TvrtOOfh4MtcROVn2rPr162PFihWW2+7uNq8SEdFVpKv78XZVtZw6n6Tj2TIR7UBMApbtjdHi7eGKDrXKomuDENxdJ5gtbSoQNo+KEphDQkJsXQ0iojyTPcSH3lVDy/7oeA3Yi3ZG4eT5JCzdE6PFXXZDq1EGXeuH4J56wSjrxy1MyUED9aFDhxAWFgZvb2+0adMG48ePR6VKlXI9NiUlRYshISGhCGtKRHQ1ydZVp6s/RnapjX1RCfhzT7TOHJeWtpFH+815u9CycmltacuYtiz/Isorm45RL1myBImJiTouHRUVpePVERER2L17N/z8/PI0pi1u1Mefnp6OtLS0Aq8/FT4PDw+4uXGLR3I8R88kWoK29RamolGFAHSpH6KBu3rZkjarI9mOw0wmyykuLg6VK1fGpEmT8OSTT96wRS1BvV69etc8UTm16OhofV5yXKVKldLhEW46QY5KdkBbtidaU3JuOX7eMntc1CxXEt0yW9r1Qv35d15MnHakyWQ5P5Br1aqFw4cP5/q4l5eXFkN8fPx1n88I0uXKlYOPjw//AzgYudBKSkpCbGys3g4NDbV1lYjyRbq6n2hXVcvZxBQs3xujQXvDkbM4FJuIQ6sOY/Kqw6hYuoSOaUtLu2nFQLjKOjAq9uwqUEs3+JEjRzBw4MBbfi7p7jaCdFBQUIHUj4peiRLmsTwJ1vK7ZDc4OTrJi/1wq0paZJ326v2xGrTXHIzFqfOX8d3fx7SU8/OydI+3qloaHkwYUmzZNFC/+uqr6Nmzp3Z3R0ZGYvTo0fpB/PDDD9/ycxtj0tKSJsdm/A7ld8pATc5Elm/1aVpey+XUdKw9aA7aK/fFIjYhBf/bdEJLKR8PdKobrK3t9jXLMDVnMeNu6z56Ccrnzp1D2bJl0b59e2zatEm/Lyjs7nZ8/B1ScVDC0w1dG4RqSb2Sod3isivasj0xOHcpFb9uO63F19MNd9Ypp0Fb8mmX9LKrjlEqBDb9Dc+aNcuWL1+sVKlSBS+99JIWWz4HEd2Yp7vsdlZOy9g+Jmw9fh5Ldkdr4I66mIw/dkZpkePuqFlG03NKXm0GbefE36qDtR5leECWqd2sLVu2wNfX9xZqRkS24ObqgtbVgrSM7lkPO09f1GVf0kV+7OwlrNgXq8XbY5d2j/dpUh531CqrQZycAwO1nZH15IbZs2fjnXfewYEDByz3lSxZMtusaJk0l5dtVwtyOIGIbHch37hiKS2vdamtM8YX74rSndGOnr2ku6NJkTFtaWX3bhyGllVKc/a4g+Mll52R9cJGCQgI0P+Yxm1JViIbwchGMc2bN9elauvWrdOZ8r1790ZwcLAG8pYtW2bbP93otv7ss88st+V5//vf/6Jv3746WatmzZpYsGDBTdX15MmT+rrymv7+/ujfvz9iYmIsj4eHh+Ouu+7SOsvjUuetW7fqYydOnNCJhIGBgdrSlz3fFy9efMvvH1FxIf+HawX74aVOtbDylQ5Y+EJ7PNm+qs4Wj0tKw8x/TuLBbzeh/UerMH7JPuyNjNeLe3I8xapFLX+kl9OyEsIXlRIebgU6IeqNN97AJ598gmrVqmmgkwXz3bt3x7hx4zR4//TTTxoEpSV+re1YhezyNmHCBHz88cf44osvMGDAAA2gpUuXvmEdMjIyLEF67dq1uHLlCoYOHYoHH3wQa9as0WPk+Zo2bYqpU6fqbO0dO3boTmNCjk1NTcVff/2lgXrv3r3ZeguIKO/k86VhhQAt/+leF5uOntN82kt2RSPyYjK+WXtUS63gkujdpLzm1Jb9yskxFKtALUG63jtLi/x1977fpUBT373//vu45557LLclsDZu3Nhye8yYMZg7d662kF944YVrPs/jjz9uWQr3wQcfYPLkydi8eTO6du16wzqsXLkSu3btwrFjx3R3HSEXCNIylvFwadVLi3vkyJGoU6eOPi6tdoM8dt9996Fhw4Z6Wy46iKhgxrTb1Sij5f3eDbDmQCzmbY/Eqv2xOBiTiI+XHtDSvHIg+jQJ0y7yoJJMGGLP2PXtgFq0aHHVRjGyJr1u3bq6u5u0TPft26fB8HoaNWpk+V5atdI9bewCdiPy/BKgjSAtZDtXeX15TIwYMQJPPfUUOnXqhA8//FC76A3Dhg3D2LFj0a5dO50gt3PnzjyfPxHljay3luVeXw9sji1vdcKE+xqhXY0gSAffthMX8Pb8PWj1wUo8MW0z5m2PwKWUK7auMhX3FrV0QUvr1havW5Byzt6WIL18+XLtDq9Ro4bu5nX//fdr1/L1GN3Q1t1n0qVdUGR2+iOPPII//vhDx9UlIMuSPBkXlwDepUsXfWzZsmWaNW3ixIl48cUXC+z1iSj75ir9W1bUEhOfjIXhkZi/IxK7Ii5i9YEzWuSzSlJy9mkahttrluVuaHaiWAVqCUQF2QVtL9avX6/d2BIAjRb28ePHC/U1pfUuY+NSjFa1jDPLtq3SsjbI3u1SXn75Ze1mnzZtmqWe8nPPPfecllGjRuG7775joCYqAsH+3njq9mpajpxJ1IC9YEcEjp9LwoLwSC2BPh7o0ShUx7SbV+K+47bkfFGrGJKx399//10nkMnFyNtvv12gLePcSHe2jC/LhDGZTS6TyYYMGYIOHTpo1/zly5d1fFpa9lWrVtVd6GTsWsalhWya0q1bNw3iFy5cwOrVqzX4E1HRkjSbI+6phZc71dR0nDIJbWF4lCYPmb7ppBZJKtKrSRh6NwnT/NtUtBionYCkBR08eDDatm2LMmXK4PXXX79hZrFbJRcE8+fP1xbwHXfcAVdXV52EJrPHhczylq1hH3vsMV2yJfXq16+fJZ+4rP+Wmd8SwGVsXH72008/LdQ6E9H1/083qVhKy5vd62Lj0XM6CU12Q5M0nVPXHNFSJ8RPg7bMHK8QyJnjRcGu8lEXZD7P5ORknZEsrTlvb2+b1ZFuHX+XRLaTnJauSUKkpb3mwBmkpmf11snGK7dnzjBvVrkUvNyZLMTp81ETEZH9zRyXsWopF5PSsGR3FObtiMA/x84j/FScli9XH4a3hytaVQ1C+xpBGrjrhvhzXLuAMFATEVGeBPh44KFWlbREX0zG34fOYP3hs1h3+JyOaf918IwWUdrXE22rS+A2t7i5wUr+MVATEdFNCwnwxgMtKmqREVTZTGXd4bMauGVntPOXUi17j4vKQT4asCVwt6kWhEBfT1ufgsNgoCYiolueiFY7xE+L7Dcu+bTDT8dh3SFz4N5+Kg4nziXhxLmTuge5bLjSICzAErhbVAnULnbKHQM1EREVKEmxKVm7pLx8Ty0kJKdh87Hzlha3tL5loxUpX689ose3qBxoCdwNygfoVqhkxkBNRESFys/bAx3rBmsRsfHJWH/kLNYdOqeBOzo+GRuOnNMi+5D7e7ujbfUyaFfTHLirBPkUaGIjR8NATURERaqcvzf6Nq2gRca3JZe2Tko7dFbXb8cnX8Gfe6K1CNlwRfYolxa3BPCyfsUriQgDNRER2Yy0lGV3NCmPtamCK+kZ2iVunk1+VpOHyIYrc7ae1mKs337n3rpoXvnGKXmdAQM1ERHZDXc3VzStFKjlhbtrIin1CrYcv2Bpce+Nite12/dN3YhHb6uE17rWgb939gRDzoapUZzUnXfeqftpXy+zVZMmTYq0TkREN8vH0x0dapXFf7rXxeLht2Pzmx3Rv4V5Jy/Zh7zTxLVYsitKu9CdFQO1nZHEGrLvdW7+/vtv7SZi7mYiKq7K+Xljwv2NMfPp1qhaxhexCSl4fsa/ePqnrYiMuwxnZDeB+sMPP9QgdL1WYHHw5JNPam5p2Qc2J0kRKZmpGjVqZJO6ERHZi7bVy2DJ8Nsx7O4a8HBzwYp9sbhn0lr8sO4Y0jOcq3VtF4Fa0h9+8803DEAA7r33XpQtWxY//vhjtvslx/Qvv/yigVyyUklu5/Lly8PHx0fTTf7888+39LqSFvP999/XzeG9vLy0W/zPP/+0PJ6amooXXngBoaGhmhijcuXKGD9+vD4mXU7SlV6pUiX92bCwMAwbNuyW6kNEdCPeHm4Y0bk2Fg+7XddhX0pNx/uL9qLfV+uxJ/IinIXNA7UEIMlp/N133yEwMLBoXjT10rVLWvJNHJujmyW3Y26Su7u7poaUQG095iJBWlJDSoCWbFLNmzfHH3/8gd27d+OZZ57BwIEDsXnz5ny/JZ9//jkmTpyITz75RLvWu3Tpgl69euHQoUP6+OTJk7FgwQLMmTMHBw4cwIwZM1ClShV97LffftMUlXKxJcfPmzdPLx6IiIpCzWA/zHm2Dcb1bQA/L3fNq93ry/UYv2QfLqemw9HZfNa35CTu0aMHOnXqhLFjxxbNi34Qdu3HanYGBvySdfvjGkBaUu7HVm4PPPFH1u3PGgJJ57If8+7NX9VJbumPP/4Ya9eu1UlhRrf3fffdh4CAAC2vvvqq5XjJCb106VINoq1atUJ+SICWPNYPPfSQ3v7oo4+wevVqfPbZZ5gyZQpOnjyJmjVron379jpEIS1qgzwWEhKiv0MPDw9tWee3HkRE+eHq6oIBrSujU91gvLdwDxbvisY3a49i8a4ojO3TUCekOSqbtqhnzZqFf//919KFeiMpKSmIj4+3lISEBDijOnXqoG3btvjhhx/09uHDh3UimXR7C2lZjxkzRlutpUuXRsmSJTVQS8DMD3kvIyMj0a5du2z3y+19+/bp948//jh27NiB2rVra7f2smXLLMc98MADuHz5MqpVq4ann34ac+fOxZUrV27hHSAiyp9gf298NaA5/vtYC4QFeOPU+csY9MNmvDRru2b4ckQ2a1FLsuzhw4frxCkZ88wLCejvvfferb/4fyKv/ZhLjo3hRx6+zrE5rnNe2oWCIkFZWsrSmpXWdPXq1dGhQwd9TFrb0lUtrV0J1r6+vjoJT8aRC0uzZs1w7NgxLFmyBCtWrED//v21Bf3rr79q8nPpDpf75fc5ZMgQS4+AtLCJiIpap3rBuK16ECYuO4AfNxzHvB2RWHPwjC7zeqB5BYfaktRmLept27YhNjZWA4CMy0qRD3YZC5XvpdWY06hRo3Dx4kVL2bt3b/5e3NP32sXD+yaOLXHjY/NJAqGrqytmzpyJn376SbvDjT+s9evXo3fv3nj00UfRuHFjbckePHgw36/l7++vE8Dkea3J7Xr16mU77sEHH9T5BLNnz9ax6fPnz+tjJUqU0KVl8vtbs2YNNm7ciF27Cu7ChYjoZpX0csfonvUxb0g71A31R1xSGl77dSce+e4fHD2TCEdhsxZ1x44dr/ogf+KJJ7TbV8ZK3dyuTnkmM4qlWHfZOivpzpagKBcncp7S9WyQsWJpyW7YsEEn4E2aNAkxMTHZgurNGjlyJEaPHq0td5nxLa146eqWSWNCXkNmfDdt2lQvIGRym4xLlypVSie+yYVV69atdRb69OnTNXBbj2MTEdlK44qlsOCFdrp069MVB3U/8a6f/40X76qBZztU1+xd9sxmgdrPzw8NGjTIdp904QYFBV11f3El3d/ff/89unfvri1ew1tvvYWjR4/qzGwJjDLru0+fPtrLkF8y7iw//8orr2hPhwR9meUtFwXG72vChAk6q1suolq2bInFixdr0JZgLevgR4wYoQFbuuMXLlyov0siInvg4eaqQbl7w1C8OW83/jp4BhOXH8SC8EiM79cQLarY777hLiY72ndNZjhLa07GXvNCNgWR8VEZ75b1v9ZkCZOMqVatWjXPY+Bkn/i7JKKCJGFPAvT7C/fi3CXz3J4Brc37hgeUKJp5NdeLX3a3PMuajG0SEREVJhcXF/RuUl6XbH2weJ9m5Zrxz0ks3xuD93rVR9cGIXY12cy+O+aJiIgKSSkfT903/Oenb0M1O943nIGaiIiKtTbVgzQzl73uG85ATURExZ63He8bzkBNRESU277h3lb7hi+23b7hTh+o7WhSO+UTf4dEZIt9w1eO6IAeDUO1+/ubv46i82dr8fehM0VfHzgpY+vKpKRrJNQgh2H8DrkdKREVpXL+3pgyoFm2fcMPRBd9jgm7Wp5VkGRTDtmIQzbvELIxiD1Nt6e8taQlSMvvUH6Xue1WR0RUVPuGz9h0Ao+3Naf3LUpOG6iFbHEpjGBNjkmCtPG7JCKy1b7hsrOZLTh1oJYWtOxPXa5cOaSlpdm6OpQP0t3NljQRFWdOHagN8kHPD3siInJETjuZjIiIyBkwUBMREdkxBmoiIiI75tBj1BkZGfo1KirK1lUhIiLKMyNuGXHMaQN1TEyMfm3VqpWtq0JERJSvOFapUqXrHuNicuD9Ga9cuYLt27cjODgYrq633oufkJCAevXqYe/evfDz8yuQOhYHfN/yj+9d/vB9yz++d/bxvklLWoJ006ZN4e7u7ryBuqDFx8cjICAAFy9ehL+/v62r4zD4vuUf37v84fuWf3zvHO9942QyIiIiO8ZATUREZMcYqK14eXlh9OjR+pXyju9b/vG9yx++b/nH987x3jeOURMREdkxtqiJiIjsGAM1ERGRHWOgJiIismMM1JmmTJmCKlWqwNvbG61bt8bmzZttXSW7N378eLRs2VIX/0vO7z59+uDAgQO2rpbD+fDDDzV3+ksvvWTrqjiEiIgIPProowgKCkKJEiXQsGFDbN261dbVsmvp6el4++23UbVqVX3PqlevjjFjxoBTlK72119/oWfPnggLC9P/l/Pmzcv2uLxn77zzDkJDQ/W97NSpEw4dOoTCxEANYPbs2RgxYoTO6Pv333/RuHFjdOnSBbGxsbauml1bu3Ythg4dik2bNmH58uVIS0tD586dcenSJVtXzWFs2bIF33zzDRo1amTrqjiECxcuoF27dvDw8MCSJUt0l6iJEyciMDDQ1lWzax999BGmTp2KL7/8Evv27dPbEyZMwBdffGHrqtmdS5cuaQyQxltu5H2bPHkyvv76a/zzzz/w9fXVeJGcnFx4lZJZ38Vdq1atTEOHDrXcTk9PN4WFhZnGjx9v03o5mtjYWLk8N61du9bWVXEICQkJppo1a5qWL19u6tChg2n48OG2rpLde/31103t27e3dTUcTo8ePUyDBw/Odl+/fv1MAwYMsFmdHAEA09y5cy23MzIyTCEhIaaPP/7Ycl9cXJzJy8vL9PPPPxdaPYp9izo1NRXbtm3T7guD7Bsutzdu3GjTujka2VpPlC5d2tZVcQjSG9GjR49sf3t0fQsWLECLFi3wwAMP6HCL7JP83Xff2bpadq9t27ZYuXIlDh48qLfDw8Oxbt06dOvWzdZVcyjHjh1DdHR0tv+zsq2oDJcWZrxw6OxZBeHs2bM6fiOJPazJ7f3799usXo5GNpiXMVbplmzQoIGtq2P3Zs2apcMs0vVNeXf06FHtwpWhqv/85z/6/g0bNgyenp4YNGiQratnt9544w3dq7pOnTpwc3PTz7xx48ZhwIABtq6aQ4mOjtavucUL47HCUOwDNRVc63D37t16lU7Xd+rUKQwfPlzH9WXyIt3cBaG0qD/44AO9LS1q+buT8UIG6mubM2cOZsyYgZkzZ6J+/frYsWOHXljLhCm+b/av2Hd9lylTRq8wjdzWBrkdEhJis3o5khdeeAGLFi3C6tWrUaFCBVtXx+7JUItMVGzWrJmmt5MiE/Nkgop8L60dyp3MtJVUg9bq1q2LkydP2qxOjmDkyJHaqn7ooYd0lvzAgQPx8ssv68oNyjsjJhR1vCj2gVq6zJo3b67jN9ZX7XK7TZs2Nq2bvZO5FhKk586di1WrVunSD7qxjh07YteuXdqqMYq0EqUbUr6XC0fKnQyt5FwCKOOulStXtlmdHEFSUpLOvbEmf2fyWUd5J59xEpCt44UMKcjs78KMF+z6BnS8S7p/5MOyVatW+Oyzz3SK/hNPPGHrqtl9d7d0pc2fP1/XUhtjNDK5QtYXUu7kvco5ji9LPGRdMMf3r09agTIxSrq++/fvr/sdfPvtt1ro2mRdsIxJV6pUSbu+t2/fjkmTJmHw4MG2rprdSUxMxOHDh7NNIJMLaJkkK++fDBmMHTsWNWvW1MAt69NlCEH2kSg0hTaf3MF88cUXpkqVKpk8PT11udamTZtsXSW7J38+uZVp06bZumoOh8uz8m7hwoWmBg0a6JKYOnXqmL799ltbV8nuxcfH69+XfMZ5e3ubqlWrZnrzzTdNKSkptq6a3Vm9enWun2uDBg2yLNF6++23TcHBwfo32LFjR9OBAwcKtU7MnkVERGTHiv0YNRERkT1joCYiIrJjDNRERER2jIGaiIjIjjFQExER2TEGaiIiIjvGQE1ERGTHGKiJiIjsGAM1Ed0yFxcXzJs3z9bVIHJKDNREDu7xxx/XQJmzdO3a1dZVI6ICwKQcRE5AgvK0adOy3efl5WWz+hBRwWGLmsgJSFCW9HvWJTAwUB+T1vXUqVPRrVs3zWpWrVo1/Prrr9l+XtJu3n333fq4ZPF65plnNIuQtR9++EEzL8lrSV5oSXFq7ezZs+jbty98fHw0s9CCBQssj124cEHTeJYtW1ZfQx7PeWFBRLljoCYqBiQV33333Yfw8HANmA899BD27dunj0lK1y5dumhg37JlC3755ResWLEiWyCWQC9pTSWAS1CXIFyjRo1sr/Hee+9p6smdO3eie/fu+jrnz5+3vP7evXuxZMkSfV15vjJlyhTxu0DkoAo1NxcRFTpJv+fm5mby9fXNVsaNG6ePy3/z5557LtvPtG7d2vT888/r95ImMjAw0JSYmGh5/I8//jC5urqaoqOj9XZYWJimRbwWeY233nrLclueS+5bsmSJ3u7Zs6fpiSeeKOAzJyoeOEZN5ATuuusubaVak0T3hjZt2mR7TG7v2LFDv5cWbuPGjeHr62t5vF27dsjIyMCBAwe06zwyMhIdO3a8bh0aNWpk+V6ey9/fH7GxsXr7+eef1xb9v//+i86dO6NPnz5o27btLZ41UfHAQE3kBCQw5uyKLigyppwXHh4e2W5LgJdgL2R8/MSJE1i8eDGWL1+uQV+60j/55JNCqTORM+EYNVExsGnTpqtu161bV7+XrzJ2LWPVhvXr18PV1RW1a9eGn58fqlSpgpUrV95SHWQi2aBBgzB9+nR89tln+Pbbb2/p+YiKC7aoiZxASkoKoqOjs93n7u5umbAlE8RatGiB9u3bY8aMGdi8eTO+//57fUwmfY0ePVqD6LvvvoszZ87gxRdfxMCBAxEcHKzHyP3PPfccypUrp63jhIQEDeZyXF688847aN68uc4al7ouWrTIcqFARNfHQE3kBP78809dMmVNWsP79++3zMieNWsWhgwZosf9/PPPqFevnj4my6mWLl2K4cOHo2XLlnpbxpMnTZpkeS4J4snJyfj000/x6quv6gXA/fffn+f6eXp6YtSoUTh+/Lh2pd9+++1aHyK6MReZUZaH44jIQclY8dy5c3UCFxE5Ho5RExER2TEGaiIiIjvGMWoiJ8fRLSLHxhY1ERGRHWOgJiIismMM1ERERHaMgZqIiMiOMVATERHZMQZqIiIiO8ZATUREZMcYqImIiOwYAzURERHs1/8DJ1/2sp5PVLMAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decoding Strategies to control randomness",
   "id": "2259581e4a6b8cae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T10:12:53.501110Z",
     "start_time": "2025-06-08T10:12:52.900890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "result = complete_text(\"at the start of\", model,15)\n",
    "print(\"Output text:\\n\", result)\n"
   ],
   "id": "3d1a23fc72ed2dfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " at the start of the war, and Austria-Hungary and the German Army, and the\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Sample decoding:\n",
    "- Greedy decoding: Select the word with the highest probability (argmax) at each step.\n",
    "\n",
    "- Sampling decoding: Randomly sample the next word from the probability distribution, for example using torch.multinomial."
   ],
   "id": "1e8356fb7cec29a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T10:34:46.237016Z",
     "start_time": "2025-06-08T10:34:46.172245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "input_text = \"at the start of the\"\n",
    "input_tensor = text_to_tensor(input_text, tokenizer)\n",
    "print(\"Input tensor: \", input_tensor)\n",
    "\n",
    "logits = model(input_tensor)\n",
    "print(\"Shape of logits: \", logits.shape)\n",
    "\n",
    "next_token_logits = logits[:, -1, :]\n",
    "print(\"Shape of next_token_logits: \", next_token_logits.shape)\n",
    "print(\"next_token_logits: \", next_token_logits)\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=-1)\n",
    "next_token_id = torch.argmax(probas, dim=-1).item()\n",
    "print(\"Next token id: \", next_token_id)\n",
    "\n",
    "next_token = tokenizer.decode(next_token_id)\n",
    "print(\"Next token: \", next_token)"
   ],
   "id": "889955a772ef919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor:  tensor([[265, 262, 923, 286, 262]])\n",
      "Shape of logits:  torch.Size([1, 5, 50257])\n",
      "Shape of next_token_logits:  torch.Size([1, 50257])\n",
      "next_token_logits:  tensor([[-0.5187,  1.7607, -3.7612,  ..., -3.7995, -3.3927, -3.2070]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Next token id:  1175\n",
      "Next token:   war\n"
     ]
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T10:34:48.932964Z",
     "start_time": "2025-06-08T10:34:48.927538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(\"Next token id: \", next_token_id)\n",
    "next_token = tokenizer.decode(next_token_id)\n",
    "print(\"Next token: \", next_token)"
   ],
   "id": "9372b48e12516e8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token id:  34158\n",
      "Next token:   Ottoman\n"
     ]
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T10:46:06.842841Z",
     "start_time": "2025-06-08T10:46:06.561171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(100)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=probas.shape[-1])\n",
    "    for id, freq in enumerate(sampled_ids):\n",
    "        if freq > 1:\n",
    "            print(f\"{freq} x {tokenizer.decode(id)}\")\n",
    "\n",
    "print_sampled_tokens(probas)\n"
   ],
   "id": "7bf3b0001a1e6267",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 x  V\n",
      "2 x  first\n",
      "2 x  two\n",
      "3 x  war\n",
      "2 x  Aust\n",
      "2 x  First\n",
      "2 x  League\n",
      "4 x  French\n",
      "2 x  Pacific\n",
      "2 x  Som\n",
      "2 x  Germans\n",
      "2 x  Triple\n",
      "4 x  Allies\n",
      "3 x  Ottoman\n",
      "2 x  Petro\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T11:11:13.577157Z",
     "start_time": "2025-06-08T11:11:13.573354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-1)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1.0, 0.5, 1.5]\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ],
   "id": "607b02e4c0c3d030",
   "outputs": [],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T11:13:33.822654Z",
     "start_time": "2025-06-08T11:13:33.513591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Optional: Provide vocab list or tokenizer for better x-axis labels\n",
    "tokens = [f\"{tokenizer.decode(i)}\" for i in range(logits.shape[-1])]  # Replace with actual tokens if available\n",
    "\n",
    "# Plotting\n",
    "x = torch.arange(len(tokens))\n",
    "bar_width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for i, T in enumerate(temperatures):\n",
    "    ax.bar(x + i * bar_width, scaled_probas[i].detach().cpu(), width=bar_width, label=f\"T = {T}\")\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x + bar_width * (len(temperatures) - 1) / 2)\n",
    "ax.set_xticklabels(tokens, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4a75ae4015c447b0",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (10,) and arg 1 with shape (1, 50257).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[239], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m fig, ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, T \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(temperatures):\n\u001B[0;32m---> 15\u001B[0m     \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbar_width\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaled_probas\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbar_width\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mT = \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mT\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m ax\u001B[38;5;241m.\u001B[39mset_ylabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProbability\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     18\u001B[0m ax\u001B[38;5;241m.\u001B[39mset_xticks(x \u001B[38;5;241m+\u001B[39m bar_width \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mlen\u001B[39m(temperatures) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/matplotlib/__init__.py:1476\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[0;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1473\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m   1474\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1475\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1476\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1477\u001B[0m \u001B[43m            \u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1478\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1479\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1481\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1482\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[1;32m   1483\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py:2520\u001B[0m, in \u001B[0;36mAxes.bar\u001B[0;34m(self, x, height, width, bottom, align, **kwargs)\u001B[0m\n\u001B[1;32m   2517\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m yerr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2518\u001B[0m         yerr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_dx(yerr, y0, y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_yunits)\n\u001B[0;32m-> 2520\u001B[0m x, height, width, y, linewidth, hatch \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2521\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Make args iterable too.\u001B[39;49;00m\n\u001B[1;32m   2522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43matleast_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlinewidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2524\u001B[0m \u001B[38;5;66;03m# Now that units have been converted, set the tick locations.\u001B[39;00m\n\u001B[1;32m   2525\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m orientation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/numpy/lib/_stride_tricks_impl.py:551\u001B[0m, in \u001B[0;36mbroadcast_arrays\u001B[0;34m(subok, *args)\u001B[0m\n\u001B[1;32m    544\u001B[0m \u001B[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001B[39;00m\n\u001B[1;32m    545\u001B[0m \u001B[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001B[39;00m\n\u001B[1;32m    546\u001B[0m \u001B[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001B[39;00m\n\u001B[1;32m    547\u001B[0m \u001B[38;5;66;03m#                  order='C').itviews\u001B[39;00m\n\u001B[1;32m    549\u001B[0m args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(np\u001B[38;5;241m.\u001B[39marray(_m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, subok\u001B[38;5;241m=\u001B[39msubok) \u001B[38;5;28;01mfor\u001B[39;00m _m \u001B[38;5;129;01min\u001B[39;00m args)\n\u001B[0;32m--> 551\u001B[0m shape \u001B[38;5;241m=\u001B[39m \u001B[43m_broadcast_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(array\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m shape \u001B[38;5;28;01mfor\u001B[39;00m array \u001B[38;5;129;01min\u001B[39;00m args):\n\u001B[1;32m    554\u001B[0m     \u001B[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001B[39;00m\n\u001B[1;32m    555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m args\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/numpy/lib/_stride_tricks_impl.py:431\u001B[0m, in \u001B[0;36m_broadcast_shape\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;124;03msupplied arrays against each other.\u001B[39;00m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;66;03m# consistently\u001B[39;00m\n\u001B[0;32m--> 431\u001B[0m b \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001B[39;00m\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pos \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m32\u001B[39m, \u001B[38;5;28mlen\u001B[39m(args), \u001B[38;5;241m31\u001B[39m):\n\u001B[1;32m    434\u001B[0m     \u001B[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001B[39;00m\n\u001B[1;32m    435\u001B[0m     \u001B[38;5;66;03m# objects (it treats them as scalars)\u001B[39;00m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;66;03m# use broadcasting to avoid allocating the full array\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (10,) and arg 1 with shape (1, 50257)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T11:11:19.223051Z",
     "start_time": "2025-06-08T11:11:19.218426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(next_token_logits)\n",
    "print(scaled_probas)\n",
    "print(scaled_probas[1].shape)\n",
    "print(scaled_probas[1])"
   ],
   "id": "e51b4dc5c81f3cd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5187,  1.7607, -3.7612,  ..., -3.7995, -3.3927, -3.2070]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[tensor([[2.7040e-05, 2.6420e-04, 1.0564e-06,  ..., 1.0167e-06, 1.5271e-06,\n",
      "         1.8386e-06]], grad_fn=<SoftmaxBackward0>), tensor([[9.9772e-08, 9.5251e-06, 1.5229e-10,  ..., 1.4106e-10, 3.1822e-10,\n",
      "         4.6130e-10]], grad_fn=<SoftmaxBackward0>), tensor([[5.9636e-05, 2.7256e-04, 6.8664e-06,  ..., 6.6934e-06, 8.7784e-06,\n",
      "         9.9350e-06]], grad_fn=<SoftmaxBackward0>)]\n",
      "torch.Size([1, 50257])\n",
      "tensor([[9.9772e-08, 9.5251e-06, 1.5229e-10,  ..., 1.4106e-10, 3.1822e-10,\n",
      "         4.6130e-10]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 237
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
