{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pretrain on unlabeled data",
   "id": "96029241f3323c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate Text without training",
   "id": "59d0d184b619cfd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:07.735859Z",
     "start_time": "2025-06-20T12:26:04.412900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from gpt2_v1 import load_model, complete_text, text_to_tensor\n",
    "\n",
    "start_context = \"at the start of\"\n",
    "model = load_model()\n",
    "print(complete_text(start_context, model,10))"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at the start of damsiman Byeodintendent typo Immun juraiden considered\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.483253Z",
     "start_time": "2025-06-20T12:26:07.746341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2_v1 import dataloader_v1\n",
    "\n",
    "with open(\"world_war_ii.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "dataloader = dataloader_v1(raw_text,batch_size=2, context_size=4,stride=1)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"shape of input: \",inputs.shape)\n",
    "print(\"first step, input: \\n\", inputs,\"\\n targets: \\n\", targets)"
   ],
   "id": "4421717b10a6f375",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input:  torch.Size([2, 4])\n",
      "first step, input: \n",
      " tensor([[10603,  1810,   314,   393],\n",
      "        [ 1810,   314,   393,   262]]) \n",
      " targets: \n",
      " tensor([[1810,  314,  393,  262],\n",
      "        [ 314,  393,  262, 3274]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.500369Z",
     "start_time": "2025-06-20T12:26:08.497084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2_v1 import tensor_to_text,build_tokenizer\n",
    "tokenizer = build_tokenizer()\n",
    "for i in range(inputs.size(0)):\n",
    "    text = tensor_to_text(inputs[i].unsqueeze(0), tokenizer)\n",
    "    print(f\"Input {i}: {text}\")\n",
    "\n",
    "for i in range(targets.size(0)):\n",
    "    text = tensor_to_text(targets[i].unsqueeze(0), tokenizer)\n",
    "    print(f\"target {i}: {text}\")"
   ],
   "id": "ecd964b80608361d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 0: World War I or\n",
      "Input 1:  War I or the\n",
      "target 0:  War I or the\n",
      "target 1:  I or the First\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.572429Z",
     "start_time": "2025-06-20T12:26:08.512352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"shape of logits: \",logits.shape)\n",
    "print(\"shape of probas: \",probas.shape)"
   ],
   "id": "2a0917e20a6cdcf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of logits:  torch.Size([2, 4, 50257])\n",
      "shape of probas:  torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.583472Z",
     "start_time": "2025-06-20T12:26:08.579967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_token_ids = torch.argmax(probas, dim=-1) # Replace probas with logits yield same result\n",
    "print(\"shape of output_token_ids: \",output_token_ids.shape)\n",
    "print(\"output_token_ids: \\n\",output_token_ids)\n",
    "\n",
    "for i in range(output_token_ids.size(0)):\n",
    "    text = tensor_to_text(output_token_ids[i].unsqueeze(0), tokenizer)\n",
    "    print(f\"output {i}: {text}\")"
   ],
   "id": "215416f63d005e46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output_token_ids:  torch.Size([2, 4])\n",
      "output_token_ids: \n",
      " tensor([[38491,  2448, 36069, 24862],\n",
      "        [36397, 15489, 10460, 18747]])\n",
      "output 0:  constants Per Rebels myriad\n",
      "output 1:  Gathering bay 800array\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loss: Cross-Entropy and Perplexity",
   "id": "e550ca1ef5764591"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.599726Z",
     "start_time": "2025-06-20T12:26:08.597361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"shape of probas: \",probas.shape)\n",
    "print(\"shape of targets: \",targets.shape)\n",
    "print(targets)\n"
   ],
   "id": "adbeb698f6e1d36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of probas:  torch.Size([2, 4, 50257])\n",
      "shape of targets:  torch.Size([2, 4])\n",
      "tensor([[1810,  314,  393,  262],\n",
      "        [ 314,  393,  262, 3274]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.620150Z",
     "start_time": "2025-06-20T12:26:08.609938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size, seq_len = targets.shape\n",
    "target_probas = torch.empty(batch_size, seq_len)\n",
    "\n",
    "for text_idx in range(batch_size):\n",
    "    positions = torch.arange(seq_len)\n",
    "    print(\"targets: \", targets[text_idx])\n",
    "    #same as probas[0,[0,1,2,3],[1810,  314,  393,  262]], advanced indexing\n",
    "    target_probas[text_idx] = probas[text_idx, positions, targets[text_idx]]\n",
    "    print(f\"Text {text_idx + 1} target_probas:\", target_probas[text_idx])"
   ],
   "id": "f21ae3e75ca8da82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets:  tensor([1810,  314,  393,  262])\n",
      "Text 1 target_probas: tensor([9.9453e-06, 1.9495e-05, 1.4662e-05, 1.8303e-05])\n",
      "targets:  tensor([ 314,  393,  262, 3274])\n",
      "Text 2 target_probas: tensor([1.6926e-05, 2.1331e-05, 1.0184e-05, 1.8939e-05])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Cross Entropy Loss\n",
    "\n",
    "For a single classification sample, assume:\n",
    "\n",
    "- True label (one-hot):\n",
    "  $$\\mathbf{y} = (y_1, y_2, \\dots, y_C), \\quad y_i \\in \\{0, 1\\}$$\n",
    "\n",
    "- Predicted probabilities:\n",
    "  $$\\hat{\\mathbf{y}} = (\\hat{y}_1, \\hat{y}_2, \\dots, \\hat{y}_C), \\quad \\sum_{i=1}^C \\hat{y}_i = 1$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Cross Entropy Loss (General Form)\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{i=1}^C y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "If the true class is \\(k\\), the formula simplifies to:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\log(\\hat{y}_k)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Cross Entropy Over a Batch of \\(N\\) Samples\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{batch}} = - \\frac{1}{N} \\sum_{n=1}^N \\sum_{i=1}^C y_i^{(n)} \\log \\left( \\hat{y}_i^{(n)} \\right)\n",
    "$$\n"
   ],
   "id": "529a75dc72059a40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.631150Z",
     "start_time": "2025-06-20T12:26:08.627575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "neg_log_probas = torch.log(target_probas) * -1\n",
    "print(\"loss matrix: \",neg_log_probas)\n",
    "loss = torch.mean(neg_log_probas)\n",
    "print(\"loss: \",loss)"
   ],
   "id": "a7f711896f0272f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss matrix:  tensor([[11.5184, 10.8454, 11.1303, 10.9084],\n",
      "        [10.9867, 10.7553, 11.4947, 10.8743]])\n",
      "loss:  tensor(11.0642)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.647825Z",
     "start_time": "2025-06-20T12:26:08.643396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"shape of inputs: \",logits.shape) #(batch_size, seq_len, vocab_size)\n",
    "print(\"shape of targets: \",targets.shape)\n",
    "print(\"targets: \\n\",targets) #(batch_size, seq_len)\n",
    "# inputs must be raw logits (unnormalized scores), NOT probabilities\n",
    "# inputs shape: (batch_size * seq_len, vocab_size)\n",
    "# targets shape: (batch_size * seq_len,), containing class indices\n",
    "loss = torch.nn.functional.cross_entropy(logits.view(-1,logits.size(-1)), targets.view(-1))\n",
    "print(\"loss: \",loss)"
   ],
   "id": "eec9532018efd4a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of inputs:  torch.Size([2, 4, 50257])\n",
      "shape of targets:  torch.Size([2, 4])\n",
      "targets: \n",
      " tensor([[1810,  314,  393,  262],\n",
      "        [ 314,  393,  262, 3274]])\n",
      "loss:  tensor(11.0642)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Perplexity\n",
    "\n",
    "Given the average cross entropy loss \\(\\mathcal{L}\\) defined as:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\frac{1}{N} \\sum_{i=1}^N \\log P(w_i)\n",
    "$$\n",
    "\n",
    "The **perplexity** is computed by exponentiating the loss:\n",
    "\n",
    "$$\n",
    "\\mathrm{Perplexity} = e^{\\mathcal{L}}\n",
    "$$\n",
    "\n",
    "Perplexity can indeed be larger than the vocabulary size, though usually it’s not.\n"
   ],
   "id": "4a0efade7bf3a4fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.658327Z",
     "start_time": "2025-06-20T12:26:08.655925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "perplexity = torch.exp(loss)\n",
    "#Note perplexity is larger than vocab_size, which is expected, since the model is not trained yet.\n",
    "print(\"perplexity: \",perplexity)"
   ],
   "id": "7bd5f352b1a8ff22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity:  tensor(63842.8828)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Losses on the training and validation sets\n",
   "id": "43242757c26e2a3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.679717Z",
     "start_time": "2025-06-20T12:26:08.670055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If you didn't clean the empty lines, LLM may learn to add too many blanks.\n",
    "def clean_text_remove_empty_lines(text: str) -> str:\n",
    "    lines = text.splitlines()\n",
    "    non_empty_lines = [line.strip() for line in lines if line.strip() != \"\"]\n",
    "    return \"\\n\".join(non_empty_lines)\n",
    "\n",
    "with open(\"world_war_ii.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "cleaned_text = clean_text_remove_empty_lines(raw_text)\n",
    "\n",
    "print(cleaned_text[:200])\n",
    "tokens = tokenizer.encode(cleaned_text)\n",
    "print(\"Characters: \",len(cleaned_text))\n",
    "print(\"Tokens: \",len(tokens))"
   ],
   "id": "54ac217af9e00aa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World War I or the First World War (28 July 1914 – 11 November 1918), also known as the Great War, was a global conflict between two coalitions: the Allies (or Entente) and the Central Powers. Fightin\n",
      "Characters:  88775\n",
      "Tokens:  18134\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.707400Z",
     "start_time": "2025-06-20T12:26:08.693088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2_v1 import GPT_CONFIG_124M\n",
    "\n",
    "# Split text data into training and validation sets\n",
    "train_ratio = 0.8\n",
    "split_idx = int(len(cleaned_text) * train_ratio)\n",
    "train_data, val_data = cleaned_text[:split_idx], cleaned_text[split_idx:]\n",
    "print(\"Train data: \", len(train_data))\n",
    "print(\"Val data: \", len(val_data))\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = dataloader_v1(\n",
    "    train_data, batch_size=2,\n",
    "    context_size=128,\n",
    "    stride=128,\n",
    "    drop_last=True, shuffle=True)\n",
    "val_loader = dataloader_v1(\n",
    "    val_data, batch_size=2,\n",
    "    context_size=128,\n",
    "    stride=128,\n",
    "    drop_last=False, shuffle=False)\n"
   ],
   "id": "89541052c1784c96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  71020\n",
      "Val data:  17755\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.719121Z",
     "start_time": "2025-06-20T12:26:08.715770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train dataloader: \", len(train_loader))\n",
    "train_first_batch = next(iter(train_loader))\n",
    "print(train_first_batch[0].shape, train_first_batch[1].shape)\n",
    "print(\"Val dataloader: \", len(val_loader))\n",
    "val_first_batch = next(iter(val_loader))\n",
    "print(val_first_batch[0].shape, val_first_batch[1].shape)\n"
   ],
   "id": "5e5c630757c48d16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:  56\n",
      "torch.Size([2, 128]) torch.Size([2, 128])\n",
      "Val dataloader:  14\n",
      "torch.Size([2, 128]) torch.Size([2, 128])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:08.728910Z",
     "start_time": "2025-06-20T12:26:08.725563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_batch(inputs, targets, model, device):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    logits = model(inputs)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), targets.flatten(0))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def loss_loader(loader, model, device, num_batches=None):\n",
    "    if len(loader) == 0:\n",
    "        return float('nan')\n",
    "\n",
    "    total_loss = 0.0\n",
    "    # num_batches no more than len(loader), default to len(loader)\n",
    "    num_batches = min(num_batches or len(loader), len(loader))\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = loss_batch(inputs, targets, model, device)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ],
   "id": "15723db4b3ce982b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:26:10.793487Z",
     "start_time": "2025-06-20T12:26:08.744747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MPS may have some issues when training\n",
    "device = (\n",
    "    torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = loss_loader(train_loader, model, device)\n",
    "    val_loss = loss_loader(val_loader, model, device)\n",
    "print(\"Train loss: \", train_loss)\n",
    "print(\"Val loss: \", val_loss)"
   ],
   "id": "4e1fb5a7899e0d29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  10.997474551200867\n",
      "Val loss:  10.991527489253453\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "96731e56198e205c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:38:26.623223Z",
     "start_time": "2025-06-20T12:38:26.618116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, tokens_seen_track = [], [], []\n",
    "    tokens_seen, step = 0, 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tokens_seen += input_batch.numel()\n",
    "            step += 1\n",
    "\n",
    "            if step % eval_freq == 0:\n",
    "                train_loss = loss_loader(train_loader, model, device, eval_iter)\n",
    "                val_loss = loss_loader(val_loader, model, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                tokens_seen_track.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, start_context, device)\n",
    "\n",
    "    return train_losses, val_losses, tokens_seen_track\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, start_context, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        result = complete_text(start_context, model,20,GPT_CONFIG_124M,device)\n",
    "        print(result)\n",
    "    model.train()\n"
   ],
   "id": "370c1fe6bc408a88",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:39:05.840814Z",
     "start_time": "2025-06-20T12:38:34.830502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "from gpt2_v1 import GPT2Model\n",
    "import time\n",
    "\n",
    "config = copy.deepcopy(GPT_CONFIG_124M)\n",
    "config[\"context_length\"] = 128\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "# Initialize model and optimizer\n",
    "model = GPT2Model(config).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=10,\n",
    "    eval_iter=5,\n",
    "    start_context=\"at the start of\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Report execution time\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f\"Training completed in {elapsed:.2f} minutes.\")\n"
   ],
   "id": "cb32329ab923e333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000010): Train loss 8.123, Val loss 8.147\n",
      "Ep 1 (Step 000020): Train loss 7.792, Val loss 7.842\n",
      "Ep 1 (Step 000030): Train loss 7.694, Val loss 7.788\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m     18\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m---> 19\u001B[0m train_losses, val_losses, tokens_seen \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model_simple\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mat the start of\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Report execution time\u001B[39;00m\n\u001B[1;32m     33\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m60\u001B[39m\n",
      "Cell \u001B[0;32mIn[28], line 12\u001B[0m, in \u001B[0;36mtrain_model_simple\u001B[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001B[0m\n\u001B[1;32m     10\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_batch(input_batch, target_batch, model, device)\n\u001B[1;32m     11\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 12\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m tokens_seen \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m input_batch\u001B[38;5;241m.\u001B[39mnumel()\n\u001B[1;32m     15\u001B[0m step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:485\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    480\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    481\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    482\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    483\u001B[0m             )\n\u001B[0;32m--> 485\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    488\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:79\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     77\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 79\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     81\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/torch/optim/adam.py:246\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    234\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    236\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    237\u001B[0m         group,\n\u001B[1;32m    238\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    243\u001B[0m         state_steps,\n\u001B[1;32m    244\u001B[0m     )\n\u001B[0;32m--> 246\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecoupled_weight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdecoupled_weight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:147\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/torch/optim/adam.py:933\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    931\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 933\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    935\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    936\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    938\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    939\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    940\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    941\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    942\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    943\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    944\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    945\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    947\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    948\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    949\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    950\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    951\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoupled_weight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoupled_weight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    953\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/torch/optim/adam.py:405\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001B[0m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight_decay \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    403\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m decoupled_weight_decay:\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;66;03m# Perform stepweight decay\u001B[39;00m\n\u001B[0;32m--> 405\u001B[0m         \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    407\u001B[0m         \u001B[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001B[39;00m\n\u001B[1;32m    408\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m differentiable \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(weight_decay, Tensor):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.114954Z",
     "start_time": "2025-06-20T12:28:15.581293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs, tokens, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs, train_losses, label=\"Train loss\")\n",
    "    ax1.plot(epochs, val_losses, linestyle=\"--\", label=\"Val loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ],
   "id": "7d21c133b9acb67f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decoding Strategies to control randomness",
   "id": "2259581e4a6b8cae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Sample decoding:\n",
    "- Greedy decoding: Select the word with the highest probability (argmax) at each step.\n",
    "\n",
    "- Sampling decoding: Randomly sample the next word from the probability distribution, for example using torch.multinomial."
   ],
   "id": "1e8356fb7cec29a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:37:14.505306Z",
     "start_time": "2025-06-20T12:37:14.008711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "result = complete_text(\"at the start of\", model,15,device=device)\n",
    "print(\"Output text:\\n\", result)\n"
   ],
   "id": "3d1a23fc72ed2dfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " at the start of French determination and self-sacrifice.\n",
      "The Battle of the Somme\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.639231Z",
     "start_time": "2025-06-20T11:11:04.025665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "input_text = \"At the start of the\"\n",
    "input_tensor = text_to_tensor(input_text, tokenizer).to(device)\n",
    "print(\"Input tensor: \", input_tensor)\n",
    "\n",
    "logits = model(input_tensor)\n",
    "print(\"Shape of logits: \", logits.shape)\n",
    "\n",
    "next_token_logits = logits[:, -1, :]\n",
    "print(\"Shape of next_token_logits: \", next_token_logits.shape)\n",
    "print(\"next_token_logits: \", next_token_logits)\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=-1)\n",
    "next_token_id = torch.argmax(probas, dim=-1).item()\n",
    "print(\"Next token id: \", next_token_id)\n",
    "\n",
    "next_token = tokenizer.decode([next_token_id])\n",
    "print(\"Next token: \", next_token)"
   ],
   "id": "889955a772ef919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor:  tensor([[2953,  262,  923,  286,  262]], device='mps:0')\n",
      "Shape of logits:  torch.Size([1, 5, 50257])\n",
      "Shape of next_token_logits:  torch.Size([1, 50257])\n",
      "next_token_logits:  tensor([[-3.5579, -4.3514, -3.5194,  ..., -4.2062, -3.7133, -3.9114]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>)\n",
      "Next token id:  983\n",
      "Next token:   game\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.644755Z",
     "start_time": "2025-06-20T11:18:21.146225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(\"Next token id: \", next_token_id)\n",
    "next_token = tokenizer.decode([next_token_id])\n",
    "print(\"Next token: \", next_token)"
   ],
   "id": "9372b48e12516e8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token id:  2368\n",
      "Next token:   third\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.646885Z",
     "start_time": "2025-06-20T11:19:53.917788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(100)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=probas.shape[-1])\n",
    "    for id, freq in enumerate(sampled_ids):\n",
    "        if freq > 1:\n",
    "            print(f\"{freq} x {tokenizer.decode([id])}\")\n",
    "\n",
    "print_sampled_tokens(probas)\n"
   ],
   "id": "7bf3b0001a1e6267",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 x  same\n",
      "2 x  game\n",
      "2 x  United\n",
      "2 x  foot\n",
      "2 x  central\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.649310Z",
     "start_time": "2025-06-20T11:20:37.797892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "#Complete 'At the start of the'\n",
    "possible_text = \"war battle revolution novel experiment day journey movement\"\n",
    "words = possible_text.lower().split()\n",
    "vocab = {word: idx for idx, word in enumerate(words)}\n",
    "inverse_vocab = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "# Step 2: Generate random logits for each vocab token\n",
    "vocab_size = len(vocab)\n",
    "torch.manual_seed(123)\n",
    "next_token_logits = torch.normal(mean=0.0, std=4.0, size=(vocab_size,))  # increase std to increase randomness\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "\n",
    "# Pick next token by argmax\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# Decode and print the predicted token\n",
    "print(f\"Next generated token: {inverse_vocab[next_token_id]}\")\n"
   ],
   "id": "7fc286a187b0e82c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next generated token: day\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.649552Z",
     "start_time": "2025-06-19T23:55:42.672772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(100)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=probas.shape[-1])\n",
    "    for id, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[id]}\")\n",
    "\n",
    "print_sampled_tokens(probas)\n"
   ],
   "id": "d346f6d29efff149",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 x war\n",
      "31 x battle\n",
      "7 x revolution\n",
      "4 x novel\n",
      "0 x experiment\n",
      "46 x day\n",
      "1 x journey\n",
      "0 x movement\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Temperature",
   "id": "922be060512e70e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.649726Z",
     "start_time": "2025-06-20T11:21:08.303305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-1)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1.0, 0.3, 1.5]\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ],
   "id": "607b02e4c0c3d030",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.649864Z",
     "start_time": "2025-06-20T11:21:10.252174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for i, T in enumerate(temperatures):\n",
    "    ax.bar(x + i * bar_width, scaled_probas[i], width=bar_width, label=f\"T = {T}\")\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4a75ae4015c447b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### top-k Sampling",
   "id": "b04afc1b1df6d198"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.650086Z",
     "start_time": "2025-06-20T11:21:43.104646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(next_token_logits)\n",
    "top_k = 3\n",
    "top_k_logits, top_k_indices = torch.topk(next_token_logits, k=top_k, dim=-1)\n",
    "print(\"top_k_logits: \", top_k_logits)\n",
    "print(\"top_k_indices: \", top_k_indices)"
   ],
   "id": "e02a8d293b34c6dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4459,  0.4815, -1.4785, -0.9617, -4.7877,  0.8371, -3.8894, -3.0202])\n",
      "top_k_logits:  tensor([ 0.8371,  0.4815, -0.4459])\n",
      "top_k_indices:  tensor([5, 1, 0])\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.650279Z",
     "start_time": "2025-06-20T11:21:58.426120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mask out logits that are not in the top-k by setting them to -inf\n",
    "threshold = top_k_logits[-1]\n",
    "new_logits = torch.where(\n",
    "    next_token_logits < threshold,\n",
    "    torch.full_like(next_token_logits, float('-inf')),\n",
    "    next_token_logits\n",
    ")\n",
    "\n",
    "print(\"new_logits: \", new_logits)\n",
    "topk_probas = torch.softmax(new_logits, dim=-1)\n",
    "print(\"topk_probas: \", topk_probas)\n",
    "\n",
    "print_sampled_tokens(topk_probas)"
   ],
   "id": "ddc553491edd9050",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_logits:  tensor([-0.4459,  0.4815,    -inf,    -inf,    -inf,  0.8371,    -inf,    -inf])\n",
      "topk_probas:  tensor([0.1402, 0.3543, 0.0000, 0.0000, 0.0000, 0.5056, 0.0000, 0.0000])\n",
      "13 x war\n",
      "34 x battle\n",
      "0 x revolution\n",
      "0 x novel\n",
      "0 x experiment\n",
      "53 x day\n",
      "0 x journey\n",
      "0 x movement\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate text with temperature and top_k",
   "id": "7ffe86906f6a8a84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.650415Z",
     "start_time": "2025-06-19T23:55:58.931425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get logits from model\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Take logits for the last time step\n",
    "        # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k, dim=-1)  # (batch, top_k)\n",
    "            threshold = top_logits[:, -1].unsqueeze(-1) # (batch, ) -> (batch, 1)\n",
    "            logits = torch.where(\n",
    "                logits < threshold,\n",
    "                torch.full_like(logits, float('-inf')),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "            # Sample from distribution\n",
    "            idx_next = torch.multinomial(probas, num_samples=1)  # (batch, 1)\n",
    "        else:\n",
    "            # Greedy sampling\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        if eos_id is not None and idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ],
   "id": "ff5f829832467cff",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.650546Z",
     "start_time": "2025-06-19T23:56:01.700466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_tensor(\"At the start of the\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", tensor_to_text(token_ids, tokenizer))"
   ],
   "id": "ac9b0ba2afa03748",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " At the start of theConnection layoutsDiamondanson Ambassador embod Richardson militias pounded Stylesenergy Students faire Carey professor\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train on larger datasets",
   "id": "556ed64f5725c7f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:37:40.978449Z",
     "start_time": "2025-06-20T12:37:39.871956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n"
   ],
   "id": "ff5faf1f8441eadf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/bytedance/PycharmProjects/CreateYourOwnLLM/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the latest cached version of the dataset since wikitext couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'wikitext-2-raw-v1' at /Users/bytedance/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/0.0.0/b08601e04326c79dfdd32d625aee71d232d685c3 (last modified on Sun Jun  8 21:30:08 2025).\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:37:49.313487Z",
     "start_time": "2025-06-20T12:37:49.309858Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset)\n",
   "id": "c280d9385abb5ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4358\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 36718\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3760\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:37:52.255419Z",
     "start_time": "2025-06-20T12:37:52.195892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = dataset['train']\n",
    "print(train_dataset['text'][:5])\n",
    "\n",
    "val_dataset = dataset['validation']\n",
    "print(val_dataset['text'][:5])"
   ],
   "id": "7f2e6212c35aff58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' = Valkyria Chronicles III = \\n', '', ' Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n', \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"]\n",
      "['', ' = Homarus gammarus = \\n', '', ' Homarus gammarus , known as the European lobster or common lobster , is a species of clawed lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea . It is closely related to the American lobster , H. americanus . It may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . In life , the lobsters are blue , only becoming \" lobster red \" on cooking . Mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into planktonic larvae . Homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the British Isles . \\n', '']\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:37:54.505015Z",
     "start_time": "2025-06-20T12:37:54.459054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = \" \".join(train_dataset['text'])\n",
    "print(\"train_data: \", train_data[:100])\n",
    "\n",
    "val_data = \" \".join(val_dataset['text'])\n",
    "print(\"val_data: \", val_data[:100])"
   ],
   "id": "da296d1126813a91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:    = Valkyria Chronicles III = \n",
      "   Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリ\n",
      "val_data:    = Homarus gammarus = \n",
      "   Homarus gammarus , known as the European lobster or common lobster , is a\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:37:56.492921Z",
     "start_time": "2025-06-20T12:37:56.490112Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(train_data), len(val_data))",
   "id": "4262a8ea6207a3b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10929707 1145909\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:37:58.620202Z",
     "start_time": "2025-06-20T12:37:57.682356Z"
    }
   },
   "cell_type": "code",
   "source": "print(text_to_tensor(train_data,tokenizer).shape)",
   "id": "67277cdf02f4ad34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2428601])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.651625Z",
     "start_time": "2025-06-20T11:34:42.279973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(train_loader), len(val_loader))\n",
    "#2428601/16/128=1185"
   ],
   "id": "2d1b39f8f8f05c66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 123\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-21T14:01:46.388767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# from gpt2_v1 import complete_text\n",
    "import time\n",
    "# from gpt2_v1 import dataloader_v1, GPT2Model, GPT_CONFIG_124M, build_tokenizer\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "train_loader = dataloader_v1(\n",
    "    train_data, batch_size=16,\n",
    "    context_size=256,\n",
    "    stride=256,\n",
    "    drop_last=True, shuffle=True)\n",
    "val_loader = dataloader_v1(\n",
    "    val_data, batch_size=16,\n",
    "    context_size=256,\n",
    "    stride=256,\n",
    "    drop_last=False, shuffle=False)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "torch.set_num_threads(8)\n",
    "# Initialize model and optimizer\n",
    "model = GPT2Model(GPT_CONFIG_124M).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=300,\n",
    "    eval_iter=10,\n",
    "    start_context=\"at the start of\",\n",
    "    tokenizer=build_tokenizer()\n",
    ")\n",
    "\n",
    "# Report execution time\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f\"Training completed in {elapsed:.2f} minutes.\")\n"
   ],
   "id": "58cc79b344f82f2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.652582Z",
     "start_time": "2025-06-20T11:23:11.343067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#300*16*128\n",
    "print(model)"
   ],
   "id": "b130adc353ab685d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Model(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (attn): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_K): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (W_V): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.655053Z",
     "start_time": "2025-06-08T23:34:13.269419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                   num_epochs=10, eval_freq=200, eval_iter=50,\n",
    "                   start_context=\"Once upon a time\", tokenizer=tokenizer,\n",
    "                   resume_path=\"checkpoints/checkpoint_epoch4.pth\")\n"
   ],
   "id": "eb674658e5f90631",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T12:28:16.655319Z",
     "start_time": "2025-06-13T00:50:53.065334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2_v2 import GPT2Model, GPT_CONFIG_124M\n",
    "checkpoint = torch.load(\"checkpoint_epoch3.pth\", weights_only=True)\n",
    "\n",
    "model = GPT2Model(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "result = complete_text(\"at the start of\", model,15)\n",
    "print(\"Output text:\\n\", result)\n"
   ],
   "id": "f9864e8c15596da6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " at the start of the war , the first time they were defeated . \n",
      "   =\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
