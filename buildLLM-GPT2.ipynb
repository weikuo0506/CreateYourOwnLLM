{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### reBuild GPT2\n",
    "- Large means vast of parameters, 124M for GPT2"
   ],
   "id": "7fa79ab229628522"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:05:55.823948Z",
     "start_time": "2025-06-04T12:05:55.821238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:42:36.675950Z",
     "start_time": "2025-06-04T12:42:36.658642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPT2(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        batch_size, seq_len = token_ids.shape\n",
    "        token_emb = self.token_emb(token_ids)\n",
    "        pos_emb = self.pos_emb(torch.arange(seq_len, device=token_ids.device))\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.drop(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ],
   "id": "8257934d6ddfe525",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:46:43.801526Z",
     "start_time": "2025-06-04T12:46:43.795489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "texts = [\"Once upon a time there\", \"were four little Rabbits\"]\n",
    "batch = torch.stack([torch.tensor(tokenizer.encode(t)) for t in texts])\n",
    "print(batch)\n"
   ],
   "id": "1661a9f180d58ae1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7454,  2402,   257,   640,   612],\n",
      "        [22474,  1440,  1310, 22502,   896]])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:46:49.194867Z",
     "start_time": "2025-06-04T12:46:48.644839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPT2(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ],
   "id": "dd7f652d73fa2c72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 5, 50257])\n",
      "tensor([[[-0.1453, -0.5939,  0.3767,  ...,  0.4361,  0.3913,  1.1740],\n",
      "         [ 0.2646,  0.5527, -1.0897,  ...,  0.3165,  0.7068,  1.9168],\n",
      "         [-0.2009, -0.7217,  0.7162,  ...,  0.6297,  0.6221, -0.1177],\n",
      "         [ 0.1959,  0.4116,  1.1859,  ...,  2.2309,  0.2540,  0.7609],\n",
      "         [-0.4772, -0.7713,  0.6711,  ...,  0.9593, -1.1426, -1.0256]],\n",
      "\n",
      "        [[-0.7387,  0.2473, -2.2699,  ..., -0.9243, -1.1297,  0.1037],\n",
      "         [-0.5791,  1.0997, -0.4741,  ..., -0.7711,  0.9321,  1.0572],\n",
      "         [ 0.7911,  1.0512,  0.4935,  ...,  0.8441, -0.2399, -0.5090],\n",
      "         [ 1.1721,  0.9144, -0.7984,  ...,  1.6035,  0.5685,  1.0169],\n",
      "         [-1.0692, -1.7418,  0.1271,  ...,  0.1854, -0.5162, -0.7783]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Layer Norm",
   "id": "c6360de99b7446d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T13:10:23.243135Z",
     "start_time": "2025-06-04T13:10:23.237178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example = torch.randn(2, 5)\n",
    "\n",
    "layer = nn.Sequential(nn.Linear(5,6),nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)\n",
    "\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"mean:\\n\", mean)\n",
    "print(\"var:\\n\", var)"
   ],
   "id": "931493ccbaf0d132",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "var:\n",
      " tensor([[0.0192],\n",
      "        [0.0332]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T13:10:50.571018Z",
     "start_time": "2025-06-04T13:10:50.564645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example = torch.randn(2, 5)\n",
    "\n",
    "layer = nn.Sequential(nn.Linear(5,6),nn.ReLU(),nn.LayerNorm(6))\n",
    "out = layer(batch_example)\n",
    "print(out)\n",
    "\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"mean:\\n\", mean)\n",
    "print(\"var:\\n\", var)"
   ],
   "id": "aa02520974159659",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6745,  1.5470, -0.9549,  0.6431, -0.9549, -0.9549],\n",
      "        [-0.0207,  0.1228, -1.1913,  1.6619,  0.6186, -1.1913]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "mean:\n",
      " tensor([[-4.9671e-08],\n",
      "        [-1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "var:\n",
      " tensor([[0.9995],\n",
      "        [0.9997]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gelu: smoother than Relu",
   "id": "de6c580743490fea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T13:17:30.665363Z",
     "start_time": "2025-06-04T13:17:30.660439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]), nn.GELU(), nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "id": "78da61e86b543a84",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T13:25:13.158786Z",
     "start_time": "2025-06-04T13:25:13.122716Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"model structure: \\n\",FeedForward(GPT_CONFIG_124M))",
   "id": "56e6af372b84cdb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model structure: \n",
      " FeedForward(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ShortCut connections\n",
   "id": "1883843d9df5a51a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T13:39:54.255895Z",
     "start_time": "2025-06-04T13:39:54.246504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList(nn.Sequential(nn.Linear(layer_sizes[i], layer_sizes[i+1]), nn.GELU()) for i in range(len(layer_sizes)-1))\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            out = layer(x)\n",
    "            if self.use_shortcut and x.shape[-1] == out.shape[-1]:\n",
    "                x = x + out\n",
    "            else:\n",
    "                x = out\n",
    "        return x\n",
    "\n",
    "def print_gradients(model,x):\n",
    "    output = model(x)\n",
    "    target = torch.zeros_like(output)\n",
    "    loss = nn.MSELoss()(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None and 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ],
   "id": "60d9de211e4a3679",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T13:44:09.617374Z",
     "start_time": "2025-06-04T13:44:09.610145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_sizes = [3] * 5 + [1]\n",
    "\n",
    "x = torch.randn(1, 3)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "print_gradients(model, x)"
   ],
   "id": "8e1a6febe718ec3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00026235237601213157\n",
      "layers.1.0.weight has gradient mean of 8.274786523543298e-05\n",
      "layers.2.0.weight has gradient mean of 0.0007381783216260374\n",
      "layers.3.0.weight has gradient mean of 0.0012937318533658981\n",
      "layers.4.0.weight has gradient mean of 0.004788137506693602\n"
     ]
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T13:44:34.479476Z",
     "start_time": "2025-06-04T13:44:34.473223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_sizes = [3] * 5 + [1]\n",
    "\n",
    "x = torch.randn(1, 3)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model, x)"
   ],
   "id": "f4d27016d9cd9eaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.16460204124450684\n",
      "layers.1.0.weight has gradient mean of 0.17733019590377808\n",
      "layers.2.0.weight has gradient mean of 0.1964351385831833\n",
      "layers.3.0.weight has gradient mean of 0.10792218148708344\n",
      "layers.4.0.weight has gradient mean of 0.6378514766693115\n"
     ]
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformer",
   "id": "72a7c83f46a9d4dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f94f9df964ea83af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
