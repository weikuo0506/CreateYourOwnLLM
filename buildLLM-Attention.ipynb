{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîç Attention Mechanism (Scaled Dot-Product)\n",
    "\n",
    "The core formula of Attention is:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) V\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\( Q \\): Query matrix\n",
    "- \\( K \\): Key matrix\n",
    "- \\( V \\): Value matrix\n",
    "- \\( d_k \\): Dimension of the key vectors (used for scaling)\n",
    "\n",
    "### üß† Intuition\n",
    "\n",
    "The attention mechanism lets the model **focus on the most relevant input tokens** when generating each output, based on the similarity between query and key vectors.\n",
    "\n",
    "It computes a weighted sum of all values (V), where the weights are determined by how well each key (K) matches the current query (Q).\n",
    "\n"
   ],
   "id": "59a758b2dc1c4553"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Input Tokens and Random Embeddings",
   "id": "e3b7895f1134e2a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üì¶ Input Embedding Matrix $X$ with Tokens\n",
    "\n",
    "\\[\n",
    "\\begin{array}{cccc|c}\n",
    "\\text{Dim 1} & \\text{Dim 2} & \\text{Dim 3} & \\text{Dim 4} & \\text{Token} \\\\\n",
    "\\hline\n",
    "\\phantom{-}0.3374 & -0.1778 & -0.3035 & -0.5880 & \\text{\"Once\"} \\\\\n",
    "\\phantom{-}1.5810 & \\phantom{-}1.3010 & \\phantom{-}1.2753 & -0.2010 & \\text{\"upon\"} \\\\\n",
    "-0.1606 & -0.4015 & \\phantom{-}0.6957 & -1.8061 & \\text{\"a\"} \\\\\n",
    "-1.1589 & \\phantom{-}0.3255 & -0.6315 & -2.8400 & \\text{\"time\"} \\\\\n",
    "-0.7849 & -1.4096 & -0.4076 & \\phantom{-}0.7953 & \\text{\"there\"}\n",
    "\\end{array}\n",
    "\\]\n"
   ],
   "id": "74f2e6ec523e9a6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input X: torch.Size([5, 4])\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880],\n",
      "        [ 1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [-0.1606, -0.4015,  0.6957, -1.8061],\n",
      "        [-1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [-0.7849, -1.4096, -0.4076,  0.7953]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 199,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokens = [\"Once\", \"upon\", \"a\", \"time\", \"there\"]\n",
    "token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
    "embedding_dim = 4\n",
    "\n",
    "embedding_layer = nn.Embedding(num_embeddings=len(tokens), embedding_dim=embedding_dim)\n",
    "\n",
    "input_indices = torch.tensor([token_to_idx[token] for token in tokens])  # [0,1,2,3,4]\n",
    "X = embedding_layer(input_indices)\n",
    "print(\"shape of input X:\", X.shape)\n",
    "print(X)"
   ],
   "id": "76e44b3939241124"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Query, Key, and Value Matrices",
   "id": "1693840fd356b8f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:30.124964Z",
     "start_time": "2025-06-02T12:40:30.120259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "W_Q = torch.nn.Parameter(torch.rand(embedding_dim, embedding_dim), requires_grad=False)\n",
    "W_K = torch.nn.Parameter(torch.rand(embedding_dim, embedding_dim), requires_grad=False)\n",
    "W_V = torch.nn.Parameter(torch.rand(embedding_dim, embedding_dim), requires_grad=False)\n",
    "\n",
    "print(\"shape of W_Q:\", W_Q.shape)\n",
    "print(\"W_Q:\", W_Q)\n",
    "\n",
    "Q = X @ W_Q\n",
    "K = X @ W_K\n",
    "V = X @ W_V\n",
    "\n",
    "print(\"shape of Q:\", Q.shape)\n",
    "print(\"Q:\", Q)\n"
   ],
   "id": "317030b3acc175f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of W_Q: torch.Size([4, 4])\n",
      "W_Q: Parameter containing:\n",
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
      "        [0.0740, 0.8665, 0.1366, 0.1025],\n",
      "        [0.1841, 0.7264, 0.3153, 0.6871],\n",
      "        [0.0756, 0.1966, 0.3164, 0.4017]])\n",
      "shape of Q: torch.Size([5, 4])\n",
      "Q: tensor([[-0.0136, -0.3159, -0.2211, -0.2307],\n",
      "        [ 0.7839,  2.8310,  0.9140,  2.0175],\n",
      "        [-0.0858, -0.2806, -0.4474, -0.3992],\n",
      "        [-0.6501, -1.3338, -1.3449, -2.3394],\n",
      "        [-0.3515, -1.7666, -0.2669, -0.6454]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 200
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Compute similarity (dot product between Q and K):\n",
    "\n",
    "$$\n",
    "\\text{scores} = Q K^T\n",
    "$$\n"
   ],
   "id": "65cc817f97122421"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:30.146088Z",
     "start_time": "2025-06-02T12:40:30.142952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores = Q @ K.T\n",
    "print(\"shape of scores:\", scores.shape)\n",
    "print(\"scores:\", scores)"
   ],
   "id": "a90f194002861335",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of scores: torch.Size([5, 5])\n",
      "scores: tensor([[  0.3101,  -2.0474,   0.7024,   1.8280,   1.0647],\n",
      "        [ -2.5714,  17.4476,  -5.5017, -14.6920,  -9.3044],\n",
      "        [  0.6084,  -2.9632,   1.4480,   3.1775,   1.4642],\n",
      "        [  2.8736, -14.6337,   6.4597,  14.7155,   7.4156],\n",
      "        [  0.9222,  -8.1955,   1.8808,   5.9959,   4.5150]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "2. **Scale the scores:**\n",
    "\n",
    "$$\n",
    "\\text{scaled\\_scores} = \\frac{Q K^T}{\\sqrt{d_k}}\n",
    "$$\n"
   ],
   "id": "459cbf5dd1f0cb64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:30.165108Z",
     "start_time": "2025-06-02T12:40:30.162225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "attention_scores = scores / math.sqrt(embedding_dim)\n",
    "print(attention_scores)"
   ],
   "id": "d5b48ae51b9a46b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1551, -1.0237,  0.3512,  0.9140,  0.5323],\n",
      "        [-1.2857,  8.7238, -2.7508, -7.3460, -4.6522],\n",
      "        [ 0.3042, -1.4816,  0.7240,  1.5888,  0.7321],\n",
      "        [ 1.4368, -7.3169,  3.2298,  7.3577,  3.7078],\n",
      "        [ 0.4611, -4.0977,  0.9404,  2.9979,  2.2575]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Apply softmax to obtain attention weights\n",
    "\n",
    "$$\n",
    "\\text{attention\\_weights} = \\text{softmax} \\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right)\n",
    "$$"
   ],
   "id": "1da117e9a2bcc599"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:30.185576Z",
     "start_time": "2025-06-02T12:40:30.182429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x) # e_x = np.exp(x - np.max(x)) is better for stability\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "scores_np = attention_scores.detach().numpy()\n",
    "attention_weights = softmax(scores_np)\n",
    "print(attention_weights)"
   ],
   "id": "3f06d4935aa2a971",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6343656e-01 5.0282925e-02 1.9884653e-01 3.4909919e-01 2.3833480e-01]\n",
      " [4.4966473e-05 9.9994296e-01 1.0389488e-05 1.0493805e-07 1.5518635e-06]\n",
      " [1.2761034e-01 2.1395484e-02 1.9417544e-01 4.6106294e-01 1.9575578e-01]\n",
      " [2.5676459e-03 4.0538399e-07 1.5425654e-02 9.5712799e-01 2.4878288e-02]\n",
      " [4.6963401e-02 4.9190823e-04 7.5843528e-02 5.9360790e-01 2.8309324e-01]]\n"
     ]
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:30.203099Z",
     "start_time": "2025-06-02T12:40:30.200445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "print(attention_weights)"
   ],
   "id": "8be298054981555a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6344e-01, 5.0283e-02, 1.9885e-01, 3.4910e-01, 2.3833e-01],\n",
      "        [4.4966e-05, 9.9994e-01, 1.0389e-05, 1.0494e-07, 1.5519e-06],\n",
      "        [1.2761e-01, 2.1395e-02, 1.9418e-01, 4.6106e-01, 1.9576e-01],\n",
      "        [2.5676e-03, 4.0538e-07, 1.5426e-02, 9.5713e-01, 2.4878e-02],\n",
      "        [4.6963e-02, 4.9191e-04, 7.5844e-02, 5.9361e-01, 2.8309e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 204
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use the weights to compute a weighted sum of values\n",
    "\n",
    "$$\n",
    "\\text{output} = \\text{attention\\_weights} \\cdot V\n",
    "$$\n"
   ],
   "id": "2cb1f4b12af4b5f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:30.222736Z",
     "start_time": "2025-06-02T12:40:30.220200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Final output of self-attention\n",
    "output = attention_weights @ V\n",
    "print(\"shape of output:\", output.shape)\n",
    "print(output)"
   ],
   "id": "429dfd3747ca9748",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output: torch.Size([5, 4])\n",
      "tensor([[-1.0221, -1.1318, -1.0966, -1.2475],\n",
      "        [ 1.6613,  1.7716,  2.1347,  2.5049],\n",
      "        [-1.3064, -1.3985, -1.3982, -1.5418],\n",
      "        [-2.2928, -2.2490, -2.4211, -2.5138],\n",
      "        [-1.6010, -1.6693, -1.7563, -1.9028]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 205
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### build simple Self-Attention",
   "id": "13af5dc1e3eabf07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:30.240666Z",
     "start_time": "2025-06-02T12:40:30.237531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttentionV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_Q = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_K = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_V = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = x @ self.W_Q  # (seq_len, d_out)\n",
    "        K = x @ self.W_K\n",
    "        V = x @ self.W_V\n",
    "\n",
    "        scores = Q @ K.T / K.shape[-1]**0.5  # (seq_len, seq_len)\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        context = weights @ V  # (seq_len, d_out)\n",
    "        return context\n"
   ],
   "id": "52775a368b0ee39c",
   "outputs": [],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:45.295657Z",
     "start_time": "2025-06-02T12:40:45.289977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "sa = SelfAttentionV1(4, 4)\n",
    "output = sa(X)\n",
    "print(output)"
   ],
   "id": "64449b52079c1323",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0221, -1.1318, -1.0966, -1.2475],\n",
      "        [ 1.6613,  1.7716,  2.1347,  2.5049],\n",
      "        [-1.3064, -1.3985, -1.3982, -1.5418],\n",
      "        [-2.2928, -2.2490, -2.4211, -2.5138],\n",
      "        [-1.6010, -1.6693, -1.7563, -1.9028]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:40:47.996949Z",
     "start_time": "2025-06-02T12:40:47.992314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttentionV2(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_Q = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_K = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_V = nn.Linear(d_in, d_out, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.W_Q(x)  # (seq_len, d_out)\n",
    "        K = self.W_K(x)\n",
    "        V = self.W_V(x)\n",
    "\n",
    "        scores = Q @ K.transpose(-2, -1) / K.shape[-1]**0.5  # (seq_len, seq_len)\n",
    "        weights = F.softmax(scores, dim=-1)                 # (seq_len, seq_len)\n",
    "\n",
    "        context = weights @ V  # (seq_len, d_out)\n",
    "        return context\n"
   ],
   "id": "c9292e78338a2bd5",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T00:56:31.964935Z",
     "start_time": "2025-06-03T00:56:31.870365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "sa = SelfAttentionV2(4, 4)\n",
    "output = sa(X)\n",
    "print(output)"
   ],
   "id": "5016c70fcd738dfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1318, -0.1000, -0.4239, -0.0858],\n",
      "        [-0.0532,  0.2164, -0.8386, -0.1107],\n",
      "        [ 0.2318, -0.2270, -0.4083, -0.0919],\n",
      "        [ 0.4762, -0.5514, -0.2901, -0.0859],\n",
      "        [ 0.0700, -0.0399, -0.3281, -0.0728]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 219
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Casual Attention: Mask future words",
   "id": "a08feecb11056e53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:22:39.034855Z",
     "start_time": "2025-06-03T01:22:39.016933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# scores and weights shape: (seq_len, seq_len)\n",
    "print(\"shape of attention_scores matrix: \",attention_scores.shape)\n",
    "print(\"shape of attention_weights matrix: \",attention_weights.shape)\n",
    "\n",
    "# output shape: (seq_len, embedding_dim)\n",
    "print(\"shape of output matrix: \",output.shape)"
   ],
   "id": "be64df46a9baaf59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of attention_scores matrix:  torch.Size([5, 5])\n",
      "shape of attention_weights matrix:  torch.Size([5, 5])\n",
      "shape of output matrix:  torch.Size([5, 4])\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:26:46.081205Z",
     "start_time": "2025-06-03T01:26:46.075511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_size = attention_weights.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_size, context_size))\n",
    "print(mask_simple)"
   ],
   "id": "7c1110f875ce3b2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "execution_count": 244
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:26:49.097365Z",
     "start_time": "2025-06-03T01:26:49.092285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(attention_weights)\n",
    "masked_weights = attention_weights * mask_simple\n",
    "print(masked_weights)"
   ],
   "id": "f7f12fe27ef62fa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6344e-01, 5.0283e-02, 1.9885e-01, 3.4910e-01, 2.3833e-01],\n",
      "        [4.4966e-05, 9.9994e-01, 1.0389e-05, 1.0494e-07, 1.5519e-06],\n",
      "        [1.2761e-01, 2.1395e-02, 1.9418e-01, 4.6106e-01, 1.9576e-01],\n",
      "        [2.5676e-03, 4.0538e-07, 1.5426e-02, 9.5713e-01, 2.4878e-02],\n",
      "        [4.6963e-02, 4.9191e-04, 7.5844e-02, 5.9361e-01, 2.8309e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.6344e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.4966e-05, 9.9994e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2761e-01, 2.1395e-02, 1.9418e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.5676e-03, 4.0538e-07, 1.5426e-02, 9.5713e-01, 0.0000e+00],\n",
      "        [4.6963e-02, 4.9191e-04, 7.5844e-02, 5.9361e-01, 2.8309e-01]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "execution_count": 247
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:28:14.721912Z",
     "start_time": "2025-06-03T01:28:14.701749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "masked_weights_normalized = masked_weights / torch.sum(masked_weights, dim=-1, keepdim=True)\n",
    "print(masked_weights_normalized)"
   ],
   "id": "6f7bc22b05ed526e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.4967e-05, 9.9996e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.7185e-01, 6.2345e-02, 5.6581e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.6332e-03, 4.1573e-07, 1.5819e-02, 9.8155e-01, 0.0000e+00],\n",
      "        [4.6963e-02, 4.9191e-04, 7.5844e-02, 5.9361e-01, 2.8309e-01]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 248
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dropout: additional mask\n",
    "- scaled: 1 / (1 - `dropout_rate`)\n"
   ],
   "id": "8189638c4e7d4883"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T01:47:26.429116Z",
     "start_time": "2025-06-03T01:47:26.410080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Create a dropout layer with 20% dropout rate\n",
    "dropout = torch.nn.Dropout(0.2)\n",
    "dropout.train()  # Explicitly set to training mode to enable dropout\n",
    "\n",
    "example = torch.ones(100, 100)\n",
    "\n",
    "print(\"Input tensor:\")\n",
    "print(example)\n",
    "\n",
    "# Apply dropout to the input tensor\n",
    "output = dropout(example)\n",
    "\n",
    "print(\"\\nOutput tensor after Dropout:\")\n",
    "print(output)\n",
    "print(f\"\\nNumber of zeros in output: {(output == 0).sum().item()}\")\n",
    "print(f\"Output mean value (should be ~1.0 due to scaling): {output.mean().item():.4f}\")\n"
   ],
   "id": "15e8995a597bce27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor:\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "\n",
      "Output tensor after Dropout:\n",
      "tensor([[1.2500, 1.2500, 1.2500,  ..., 0.0000, 1.2500, 1.2500],\n",
      "        [0.0000, 1.2500, 0.0000,  ..., 1.2500, 1.2500, 1.2500],\n",
      "        [1.2500, 1.2500, 1.2500,  ..., 1.2500, 1.2500, 1.2500],\n",
      "        ...,\n",
      "        [1.2500, 1.2500, 0.0000,  ..., 0.0000, 1.2500, 1.2500],\n",
      "        [0.0000, 0.0000, 1.2500,  ..., 0.0000, 1.2500, 1.2500],\n",
      "        [1.2500, 1.2500, 1.2500,  ..., 1.2500, 0.0000, 1.2500]])\n",
      "\n",
      "Number of zeros in output: 1995\n",
      "Output mean value (should be ~1.0 due to scaling): 1.0006\n"
     ]
    }
   ],
   "execution_count": 259
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:34:18.763786Z",
     "start_time": "2025-06-03T13:34:18.747131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"original attention weights: \\n\", attention_weights)\n",
    "torch.manual_seed(123)\n",
    "output = dropout(attention_weights)\n",
    "print(\"Output tensor after Dropout: \\n\", output)\n"
   ],
   "id": "82719649039e7fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original attention weights: \n",
      " tensor([[1.6344e-01, 5.0283e-02, 1.9885e-01, 3.4910e-01, 2.3833e-01],\n",
      "        [4.4966e-05, 9.9994e-01, 1.0389e-05, 1.0494e-07, 1.5519e-06],\n",
      "        [1.2761e-01, 2.1395e-02, 1.9418e-01, 4.6106e-01, 1.9576e-01],\n",
      "        [2.5676e-03, 4.0538e-07, 1.5426e-02, 9.5713e-01, 2.4878e-02],\n",
      "        [4.6963e-02, 4.9191e-04, 7.5844e-02, 5.9361e-01, 2.8309e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Output tensor after Dropout: \n",
      " tensor([[2.0430e-01, 6.2854e-02, 2.4856e-01, 4.3637e-01, 2.9792e-01],\n",
      "        [5.6208e-05, 1.2499e+00, 1.2987e-05, 0.0000e+00, 1.9398e-06],\n",
      "        [0.0000e+00, 2.6744e-02, 2.4272e-01, 5.7633e-01, 2.4469e-01],\n",
      "        [3.2096e-03, 5.0673e-07, 1.9282e-02, 1.1964e+00, 3.1098e-02],\n",
      "        [5.8704e-02, 6.1489e-04, 9.4804e-02, 7.4201e-01, 3.5387e-01]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "execution_count": 323
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Casual Self-Attention code",
   "id": "50a8bb9fb69e21dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:28:04.082460Z",
     "start_time": "2025-06-03T13:28:04.071007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements single-head causal self-attention with optional dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_Q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_K = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_V = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Create a fixed causal mask (upper triangular) [1 means \"mask\"]\n",
    "        mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        self.register_buffer(\"mask\", mask.bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: shape (batch_size, seq_len, d_in)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        Q = self.W_Q(x)   # (batch_size, seq_len, d_out)\n",
    "        K = self.W_K(x)     # (batch_size, seq_len, d_out)\n",
    "        V = self.W_V(x)   # (batch_size, seq_len, d_out)\n",
    "\n",
    "        # Compute attention scores\n",
    "        scores = Q @ K.transpose(-2, -1) / (self.d_out ** 0.5)  # (batch_size, seq_len, seq_len)\n",
    "\n",
    "        # Apply causal mask\n",
    "        scores = scores.masked_fill(self.mask[:seq_len, :seq_len], -torch.inf)\n",
    "\n",
    "        # Compute softmax weights and apply dropout\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "\n",
    "        # Compute output\n",
    "        output = weights @ V  # (batch_size, seq_len, d_out)\n",
    "        return output\n"
   ],
   "id": "75e61ec943654665",
   "outputs": [],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T13:34:36.410672Z",
     "start_time": "2025-06-03T13:34:36.404573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch = torch.randn(2, 5, 4)  # (batch_size=2, seq_len=5, d_in=4)\n",
    "d_in = 4\n",
    "d_out = 4\n",
    "context_length = batch.size(1)\n",
    "\n",
    "ca = CausalAttention(d_in, d_out, context_length, dropout=0.2)\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)\n"
   ],
   "id": "75fb28f77047d208",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0609, -0.0140,  0.0562,  0.4382],\n",
      "         [-0.0324, -0.0075,  0.0299,  0.2333],\n",
      "         [-0.2897, -0.1304,  0.3230,  0.5063],\n",
      "         [-0.2048,  0.0066,  0.4691,  0.3889],\n",
      "         [ 0.0330,  0.1819,  0.4528,  0.0227]],\n",
      "\n",
      "        [[ 0.1200,  0.5322,  2.1774,  0.2556],\n",
      "         [-0.1208,  0.3467,  1.4933,  0.6279],\n",
      "         [ 0.1272,  0.2546,  0.6062,  0.2328],\n",
      "         [-0.2555, -0.0437,  0.0182,  0.4622],\n",
      "         [-0.0464, -0.0602, -0.1888,  0.1372]]], grad_fn=<UnsafeViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 5, 4])\n"
     ]
    }
   ],
   "execution_count": 329
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
