{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîç Attention Mechanism (Scaled Dot-Product)\n",
    "\n",
    "The core formula of Attention is:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) V\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\( Q \\): Query matrix\n",
    "- \\( K \\): Key matrix\n",
    "- \\( V \\): Value matrix\n",
    "- \\( d_k \\): Dimension of the key vectors (used for scaling)\n",
    "\n",
    "### üß† Intuition\n",
    "\n",
    "The attention mechanism lets the model **focus on the most relevant input tokens** when generating each output, based on the similarity between query and key vectors.\n",
    "\n",
    "It computes a weighted sum of all values (V), where the weights are determined by how well each key (K) matches the current query (Q).\n",
    "\n"
   ],
   "id": "59a758b2dc1c4553"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Input Tokens and Random Embeddings",
   "id": "e3b7895f1134e2a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üì¶ Input Embedding Matrix $X$ with Tokens\n",
    "\n",
    "\\[\n",
    "\\begin{array}{cccc|c}\n",
    "\\text{Dim 1} & \\text{Dim 2} & \\text{Dim 3} & \\text{Dim 4} & \\text{Token} \\\\\n",
    "\\hline\n",
    "\\phantom{-}0.3374 & -0.1778 & -0.3035 & -0.5880 & \\text{\"Once\"} \\\\\n",
    "\\phantom{-}1.5810 & \\phantom{-}1.3010 & \\phantom{-}1.2753 & -0.2010 & \\text{\"upon\"} \\\\\n",
    "-0.1606 & -0.4015 & \\phantom{-}0.6957 & -1.8061 & \\text{\"a\"} \\\\\n",
    "-1.1589 & \\phantom{-}0.3255 & -0.6315 & -2.8400 & \\text{\"time\"} \\\\\n",
    "-0.7849 & -1.4096 & -0.4076 & \\phantom{-}0.7953 & \\text{\"there\"}\n",
    "\\end{array}\n",
    "\\]\n"
   ],
   "id": "74f2e6ec523e9a6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T12:15:35.430538Z",
     "start_time": "2025-06-16T12:15:33.913990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokens = [\"Once\", \"upon\", \"a\", \"time\", \"there\"]\n",
    "token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
    "embedding_dim = 4\n",
    "\n",
    "embedding_layer = nn.Embedding(num_embeddings=len(tokens), embedding_dim=embedding_dim)\n",
    "\n",
    "input_indices = torch.tensor([token_to_idx[token] for token in tokens])  # [0,1,2,3,4]\n",
    "X = embedding_layer(input_indices)\n",
    "print(\"shape of input X:\", X.shape)\n",
    "print(X)"
   ],
   "id": "76e44b3939241124",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input X: torch.Size([5, 4])\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880],\n",
      "        [ 1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [-0.1606, -0.4015,  0.6957, -1.8061],\n",
      "        [-1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [-0.7849, -1.4096, -0.4076,  0.7953]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Query, Key, and Value Matrices",
   "id": "1693840fd356b8f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T12:29:45.173494Z",
     "start_time": "2025-06-16T12:29:45.163509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "W_Q = torch.nn.Parameter(torch.rand(embedding_dim, embedding_dim), requires_grad=False)\n",
    "W_K = torch.nn.Parameter(torch.rand(embedding_dim, embedding_dim), requires_grad=False)\n",
    "W_V = torch.nn.Parameter(torch.rand(embedding_dim, embedding_dim), requires_grad=False)\n",
    "\n",
    "print(\"shape of W_Q:\", W_Q.shape)\n",
    "print(\"W_Q:\", W_Q)\n",
    "\n",
    "Q = X @ W_Q\n",
    "K = X @ W_K\n",
    "V = X @ W_V\n",
    "\n",
    "print(\"shape of Q:\", Q.shape)\n",
    "print(\"Q:\", Q)\n"
   ],
   "id": "317030b3acc175f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of W_Q: torch.Size([4, 4])\n",
      "W_Q: Parameter containing:\n",
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
      "        [0.0740, 0.8665, 0.1366, 0.1025],\n",
      "        [0.1841, 0.7264, 0.3153, 0.6871],\n",
      "        [0.0756, 0.1966, 0.3164, 0.4017]])\n",
      "shape of Q: torch.Size([5, 4])\n",
      "Q: tensor([[-0.0136, -0.3159, -0.2211, -0.2307],\n",
      "        [ 0.7839,  2.8310,  0.9140,  2.0175],\n",
      "        [-0.0858, -0.2806, -0.4474, -0.3992],\n",
      "        [-0.6501, -1.3338, -1.3449, -2.3394],\n",
      "        [-0.3515, -1.7666, -0.2669, -0.6454]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Compute similarity (dot product between Q and K):\n",
    "\n",
    "$$\n",
    "\\text{scores} = Q K^T\n",
    "$$\n"
   ],
   "id": "65cc817f97122421"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T12:48:31.543978Z",
     "start_time": "2025-06-16T12:48:31.526578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores = Q @ K.T\n",
    "print(\"shape of scores:\", scores.shape)\n",
    "print(\"scores:\", scores)"
   ],
   "id": "a90f194002861335",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of scores: torch.Size([5, 5])\n",
      "scores: tensor([[  0.3101,  -2.0474,   0.7024,   1.8280,   1.0647],\n",
      "        [ -2.5714,  17.4476,  -5.5017, -14.6920,  -9.3044],\n",
      "        [  0.6084,  -2.9632,   1.4480,   3.1775,   1.4642],\n",
      "        [  2.8736, -14.6337,   6.4597,  14.7155,   7.4156],\n",
      "        [  0.9222,  -8.1955,   1.8808,   5.9959,   4.5150]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "2. **Scale the scores:**\n",
    "\n",
    "$$\n",
    "\\text{scaled\\_scores} = \\frac{Q K^T}{\\sqrt{d_k}}\n",
    "$$\n"
   ],
   "id": "459cbf5dd1f0cb64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T12:52:41.275204Z",
     "start_time": "2025-06-16T12:52:41.271018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "attention_scores = scores / math.sqrt(embedding_dim)\n",
    "print(attention_scores)"
   ],
   "id": "d5b48ae51b9a46b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1551, -1.0237,  0.3512,  0.9140,  0.5323],\n",
      "        [-1.2857,  8.7238, -2.7508, -7.3460, -4.6522],\n",
      "        [ 0.3042, -1.4816,  0.7240,  1.5888,  0.7321],\n",
      "        [ 1.4368, -7.3169,  3.2298,  7.3577,  3.7078],\n",
      "        [ 0.4611, -4.0977,  0.9404,  2.9979,  2.2575]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Apply softmax to obtain attention weights\n",
    "\n",
    "$$\n",
    "\\text{attention\\_weights} = \\text{softmax} \\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right)\n",
    "$$"
   ],
   "id": "1da117e9a2bcc599"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:12:46.423731Z",
     "start_time": "2025-06-16T13:12:46.383749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = torch.linspace(-5, 5, 200)\n",
    "scores = torch.stack([x, torch.zeros_like(x)], dim=1)\n",
    "softmax_vals = torch.softmax(scores, dim=1)\n",
    "\n",
    "plt.plot(x.numpy(), softmax_vals[:,0].numpy())\n",
    "plt.show()"
   ],
   "id": "8465200f3299e47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:16:38.964224Z",
     "start_time": "2025-06-16T13:16:38.959671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x) # e_x = np.exp(x - np.max(x)) is better for stability\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "scores_np = attention_scores.detach().numpy()\n",
    "attention_weights = softmax(scores_np)\n",
    "print(attention_weights)"
   ],
   "id": "3f06d4935aa2a971",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6343656e-01 5.0282925e-02 1.9884653e-01 3.4909919e-01 2.3833480e-01]\n",
      " [4.4966473e-05 9.9994296e-01 1.0389488e-05 1.0493805e-07 1.5518635e-06]\n",
      " [1.2761034e-01 2.1395484e-02 1.9417544e-01 4.6106294e-01 1.9575578e-01]\n",
      " [2.5676459e-03 4.0538399e-07 1.5425654e-02 9.5712799e-01 2.4878288e-02]\n",
      " [4.6963401e-02 4.9190823e-04 7.5843528e-02 5.9360790e-01 2.8309324e-01]]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:18:40.847454Z",
     "start_time": "2025-06-16T13:18:40.838655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "print(\"shape of attention_weights:\", attention_weights.shape)\n",
    "print(attention_weights)"
   ],
   "id": "8be298054981555a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of attention_weights: torch.Size([5, 5])\n",
      "tensor([[1.6344e-01, 5.0283e-02, 1.9885e-01, 3.4910e-01, 2.3833e-01],\n",
      "        [4.4966e-05, 9.9994e-01, 1.0389e-05, 1.0494e-07, 1.5519e-06],\n",
      "        [1.2761e-01, 2.1395e-02, 1.9418e-01, 4.6106e-01, 1.9576e-01],\n",
      "        [2.5676e-03, 4.0538e-07, 1.5426e-02, 9.5713e-01, 2.4878e-02],\n",
      "        [4.6963e-02, 4.9191e-04, 7.5844e-02, 5.9361e-01, 2.8309e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use the weights to compute a weighted sum of values\n",
    "\n",
    "$$\n",
    "\\text{output} = \\text{attention\\_weights} \\cdot V\n",
    "$$\n"
   ],
   "id": "2cb1f4b12af4b5f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:22:55.562901Z",
     "start_time": "2025-06-16T13:22:55.548349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Final output of self-attention\n",
    "output = attention_weights @ V\n",
    "print(\"shape of output:\", output.shape)\n",
    "print(output)"
   ],
   "id": "429dfd3747ca9748",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output: torch.Size([5, 4])\n",
      "tensor([[-1.0221, -1.1318, -1.0966, -1.2475],\n",
      "        [ 1.6613,  1.7716,  2.1347,  2.5049],\n",
      "        [-1.3064, -1.3985, -1.3982, -1.5418],\n",
      "        [-2.2928, -2.2490, -2.4211, -2.5138],\n",
      "        [-1.6010, -1.6693, -1.7563, -1.9028]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### build simple Self-Attention",
   "id": "13af5dc1e3eabf07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:28:52.465570Z",
     "start_time": "2025-06-16T13:28:52.460792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttentionV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_Q = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_K = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_V = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = x @ self.W_Q  # (seq_len, d_out)\n",
    "        K = x @ self.W_K\n",
    "        V = x @ self.W_V\n",
    "\n",
    "        scores = Q @ K.T / K.shape[-1]**0.5  # (seq_len, seq_len)\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        context = weights @ V  # (seq_len, d_out)\n",
    "        return context\n"
   ],
   "id": "52775a368b0ee39c",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:28:56.346859Z",
     "start_time": "2025-06-16T13:28:56.338375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "sa = SelfAttentionV1(4, 4)\n",
    "output = sa(X)\n",
    "print(output)"
   ],
   "id": "64449b52079c1323",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0221, -1.1318, -1.0966, -1.2475],\n",
      "        [ 1.6613,  1.7716,  2.1347,  2.5049],\n",
      "        [-1.3064, -1.3985, -1.3982, -1.5418],\n",
      "        [-2.2928, -2.2490, -2.4211, -2.5138],\n",
      "        [-1.6010, -1.6693, -1.7563, -1.9028]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:40:12.728221Z",
     "start_time": "2025-06-16T13:40:12.723871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttentionV2(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        # (d_in, d_out)\n",
    "        self.W_Q = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_K = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_V = nn.Linear(d_in, d_out, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (seq_len, d_in) x (d_in, d_out) -> (seq_len, d_out)\n",
    "        Q = self.W_Q(x)  # equal to: x @ W_Q.T\n",
    "        K = self.W_K(x)\n",
    "        V = self.W_V(x)\n",
    "\n",
    "        # (seq_len, d_out) x (d_out, seq_len) -> (seq_len, seq_len)\n",
    "        scores = Q @ K.transpose(-2, -1) / K.shape[-1]**0.5\n",
    "        # (seq_len, seq_len)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        # (seq_len, seq_len) x (seq_len, d_out) -> # (seq_len, d_out)\n",
    "        context = weights @ V\n",
    "        return context\n"
   ],
   "id": "c9292e78338a2bd5",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:40:14.374921Z",
     "start_time": "2025-06-16T13:40:14.368727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "sa = SelfAttentionV2(4, 4)\n",
    "output = sa(X)\n",
    "print(output)"
   ],
   "id": "5016c70fcd738dfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1318, -0.1000, -0.4239, -0.0858],\n",
      "        [-0.0532,  0.2164, -0.8386, -0.1107],\n",
      "        [ 0.2318, -0.2270, -0.4083, -0.0919],\n",
      "        [ 0.4762, -0.5514, -0.2901, -0.0859],\n",
      "        [ 0.0700, -0.0399, -0.3281, -0.0728]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Casual Attention: Mask future words",
   "id": "a08feecb11056e53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T01:53:15.296146Z",
     "start_time": "2025-06-17T01:53:15.279481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "context_size = attention_scores.shape[0]\n",
    "# Lower triangular mask\n",
    "mask = torch.tril(torch.ones(context_size, context_size))\n",
    "print(mask)\n",
    "mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, 0.0)\n",
    "print(mask)"
   ],
   "id": "7c1110f875ce3b2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T01:53:18.832722Z",
     "start_time": "2025-06-17T01:53:18.828711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"original scores: \\n\", attention_scores)\n",
    "# Apply mask to scores\n",
    "masked_scores = attention_scores + mask\n",
    "print(\"masked scores:\\n\", masked_scores)"
   ],
   "id": "f7f12fe27ef62fa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original scores: \n",
      " tensor([[ 0.1551, -1.0237,  0.3512,  0.9140,  0.5323],\n",
      "        [-1.2857,  8.7238, -2.7508, -7.3460, -4.6522],\n",
      "        [ 0.3042, -1.4816,  0.7240,  1.5888,  0.7321],\n",
      "        [ 1.4368, -7.3169,  3.2298,  7.3577,  3.7078],\n",
      "        [ 0.4611, -4.0977,  0.9404,  2.9979,  2.2575]], grad_fn=<DivBackward0>)\n",
      "masked scores:\n",
      " tensor([[ 0.1551,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-1.2857,  8.7238,    -inf,    -inf,    -inf],\n",
      "        [ 0.3042, -1.4816,  0.7240,    -inf,    -inf],\n",
      "        [ 1.4368, -7.3169,  3.2298,  7.3577,    -inf],\n",
      "        [ 0.4611, -4.0977,  0.9404,  2.9979,  2.2575]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dropout\n",
    "- scaled: 1 / (1 - `dropout_rate`)\n"
   ],
   "id": "8189638c4e7d4883"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T02:07:19.444770Z",
     "start_time": "2025-06-17T02:07:19.439242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Create a dropout layer with 20% dropout rate\n",
    "dropout = torch.nn.Dropout(0.2)\n",
    "dropout.train()  # Explicitly set to training mode to enable dropout\n",
    "\n",
    "example = torch.ones(5, 5)\n",
    "print(\"Input tensor:\\n\",example)\n",
    "\n",
    "# Apply dropout to the input tensor\n",
    "output = dropout(example)\n",
    "print(\"tensor after Dropout:\\n\",output)\n",
    "print(f\"Number of zeros in output: {(output == 0).sum().item()}\")\n",
    "print(f\"Output mean value (should be ~1.0 due to scaling): {output.mean().item():.4f}\")"
   ],
   "id": "15e8995a597bce27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor:\n",
      " tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor after Dropout:\n",
      " tensor([[1.2500, 1.2500, 1.2500, 1.2500, 1.2500],\n",
      "        [1.2500, 1.2500, 1.2500, 0.0000, 1.2500],\n",
      "        [0.0000, 1.2500, 1.2500, 1.2500, 1.2500],\n",
      "        [1.2500, 1.2500, 1.2500, 1.2500, 1.2500],\n",
      "        [1.2500, 1.2500, 1.2500, 1.2500, 1.2500]])\n",
      "Number of zeros in output: 2\n",
      "Output mean value (should be ~1.0 due to scaling): 1.1500\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T02:19:29.513119Z",
     "start_time": "2025-06-17T02:19:29.499655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights = F.softmax(masked_scores, dim=-1)\n",
    "print(\"weights after mask: \\n\", weights)\n",
    "torch.manual_seed(123)\n",
    "output = dropout(weights)\n",
    "print(\"weights after Dropout: \\n\", output)"
   ],
   "id": "82719649039e7fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights after mask: \n",
      " tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.4967e-05, 9.9996e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.7185e-01, 6.2345e-02, 5.6581e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.6332e-03, 4.1573e-07, 1.5819e-02, 9.8155e-01, 0.0000e+00],\n",
      "        [4.6963e-02, 4.9191e-04, 7.5844e-02, 5.9361e-01, 2.8309e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "weights after Dropout: \n",
      " tensor([[1.2500e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.6209e-05, 1.2499e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.7931e-02, 7.0726e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.2914e-03, 5.1966e-07, 1.9774e-02, 1.2269e+00, 0.0000e+00],\n",
      "        [5.8704e-02, 6.1489e-04, 9.4804e-02, 7.4201e-01, 3.5387e-01]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Casual Self-Attention code",
   "id": "50a8bb9fb69e21dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T06:26:06.162980Z",
     "start_time": "2025-06-17T06:26:06.157415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements single-head causal self-attention with optional dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_in, d_out, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        # (d_in, d_out)\n",
    "        self.W_Q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_K = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_V = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Create a fixed causal mask (upper triangular) [1 means \"mask\"]\n",
    "        mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        self.register_buffer(\"mask\", mask.bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: shape (batch_size, seq_len, d_in)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        Q = self.W_Q(x)\n",
    "        K = self.W_K(x)\n",
    "        V = self.W_V(x)\n",
    "\n",
    "        # Compute attention scores\n",
    "        scores = Q @ K.transpose(-2, -1) / (d_out ** 0.5)  # (batch_size, seq_len, seq_len)\n",
    "\n",
    "        # Apply causal mask\n",
    "        scores = scores.masked_fill(self.mask[:seq_len, :seq_len], -torch.inf)\n",
    "\n",
    "        # Compute softmax weights and apply dropout\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "\n",
    "        # Compute output\n",
    "        output = weights @ V  # (batch_size, seq_len, d_out)\n",
    "        return output\n"
   ],
   "id": "75e61ec943654665",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T06:27:25.813457Z",
     "start_time": "2025-06-17T06:27:25.802716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch = torch.randn(2, 5, 4)  # (batch_size=2, seq_len=5, d_in=4)\n",
    "d_in = 4\n",
    "d_out = 4\n",
    "context_length = batch.size(1)\n",
    "\n",
    "ca = CausalAttention(d_in, d_out, context_length, dropout=0.0)\n",
    "context_vecs = ca(batch)\n",
    "\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)\n",
    "print(\"context_vecs:\\n\", context_vecs)"
   ],
   "id": "75fb28f77047d208",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([2, 5, 4])\n",
      "context_vecs:\n",
      " tensor([[[-0.0487, -0.0112,  0.0449,  0.3506],\n",
      "         [ 0.0439,  0.1278,  0.1848,  0.1733],\n",
      "         [-0.2467, -0.1078,  0.2722,  0.5128],\n",
      "         [-0.1638,  0.0053,  0.3753,  0.3111],\n",
      "         [ 0.0264,  0.1455,  0.3622,  0.0182]],\n",
      "\n",
      "        [[ 0.0960,  0.4257,  1.7419,  0.2045],\n",
      "         [-0.0967,  0.2774,  1.1946,  0.5023],\n",
      "         [ 0.1017,  0.2037,  0.4849,  0.1862],\n",
      "         [-0.0775,  0.1062,  0.3737,  0.3387],\n",
      "         [-0.1181, -0.0113,  0.1070,  0.2743]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Multi-head Attention\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch03_compressed/24.webp\" width=\"800px\">\n"
   ],
   "id": "71c18a8cec63347c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T06:59:17.587592Z",
     "start_time": "2025-06-17T06:59:17.570115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements multi-head self-attention by stacking multiple heads.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, self.head_dim, context_length, dropout, qkv_bias) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return output"
   ],
   "id": "e135ed0ca97135cb",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T06:59:28.125473Z",
     "start_time": "2025-06-17T06:59:28.118566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch = torch.randn(2, 5, 6)  # (batch_size=2, seq_len=5, d_in=6)\n",
    "d_in = 6\n",
    "d_out = 6\n",
    "context_length = batch.size(1)\n",
    "\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, dropout=0.0,num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)\n",
    "print(\"context_vecs:\\n\", context_vecs)\n"
   ],
   "id": "e320e7b01e3fce7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([2, 5, 6])\n",
      "context_vecs:\n",
      " tensor([[[-0.0067, -0.0370,  0.2712, -0.5243, -0.0242, -0.0438],\n",
      "         [-0.1782,  0.0173, -0.0166, -0.2391, -0.0284,  0.2177],\n",
      "         [-0.1541,  0.2878, -0.2018,  0.2535,  0.0242,  0.3002],\n",
      "         [-0.2817,  0.5219, -0.0699,  0.5508, -0.2767,  0.3709],\n",
      "         [-0.0355, -0.1721,  0.0981,  0.2389, -0.1460,  0.1938]],\n",
      "\n",
      "        [[ 0.7943, -1.9382,  0.2171, -1.6710,  0.7970, -1.3094],\n",
      "         [ 0.2519, -1.1446,  0.2991, -1.5203,  0.3135, -0.9541],\n",
      "         [ 0.1920, -0.8646,  0.3794, -0.9135,  0.0203, -0.5454],\n",
      "         [ 0.2565, -0.8320,  0.1292, -0.9259,  0.2156, -0.4762],\n",
      "         [ 0.1519, -0.5043,  0.1079, -0.3281,  0.1523, -0.1446]]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This version of `MultiHeadAttention` is closer to real-world implementations, such as in GPT models.\n",
    "- Instead of multiple separate `CausalAttention` modules, it splits `Q`, `K`, `V` into multiple heads via reshaping.\n",
    "- It uses a causal mask to ensure autoregressive behavior (no peeking into the future).\n"
   ],
   "id": "f9946bb3409556ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T07:25:55.146600Z",
     "start_time": "2025-06-17T07:25:55.137316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements multi-head attention by splitting the attention matrix into multiple heads.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_Q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_K = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_V = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_O = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        self.register_buffer(\"mask\", mask.bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape (batch_size, seq_len, d_in)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Split Q, K, V into multiple heads\n",
    "        # (batch_size, seq_len, d_in) -> (batch_size, seq_len, d_out) ->\n",
    "        # -> (batch_size, seq_len, num_heads, head_dim) -> (batch_size, num_heads, seq_len, head_dim)\n",
    "        Q = self.W_Q(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.W_K(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.W_V(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Compute attention scores\n",
    "        scores = Q @ K.transpose(-2, -1) / (self.d_out ** 0.5)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "\n",
    "        # Apply causal mask\n",
    "        scores = scores.masked_fill(self.mask[:seq_len, :seq_len], -torch.inf)\n",
    "\n",
    "        # Compute softmax weights and apply dropout\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "\n",
    "        # Compute output\n",
    "        output = weights @ V  # (batch_size, num_heads, seq_len, head_dim)\n",
    "        # Concatenate heads and project to output dimension\n",
    "        # (batch_size, num_heads, seq_len, head_dim) -> (batch_size, seq_len, num_heads, head_dim)\n",
    "        # ->   (batch_size, seq_len, d_out)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, -1)\n",
    "        # Should be helpful, but not strictly necessary.\n",
    "        output = self.W_O(output)\n",
    "        return output\n"
   ],
   "id": "6ff7e0f86dd853d0",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T07:29:01.407146Z",
     "start_time": "2025-06-17T07:29:01.395477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch = torch.randn(2, 5, 6)  # (batch_size=2, seq_len=5, d_in=6)\n",
    "d_in = 6\n",
    "d_out = 6\n",
    "context_length = batch.size(1)\n",
    "\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, dropout=0.0,num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)\n",
    "print(\"context_vecs:\\n\", context_vecs)"
   ],
   "id": "70654944612728eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([2, 5, 6])\n",
      "context_vecs:\n",
      " tensor([[[-0.5829, -0.5644,  0.1930, -0.1541,  0.2518, -0.2252],\n",
      "         [-0.2962, -0.2681,  0.1179,  0.1136,  0.0953, -0.4015],\n",
      "         [-0.2039, -0.0745,  0.1557, -0.0494,  0.1125, -0.5282],\n",
      "         [-0.2540,  0.1181,  0.2729, -0.1182,  0.0321, -0.5292],\n",
      "         [-0.2007,  0.0280,  0.1645, -0.0798,  0.1264, -0.5020]],\n",
      "\n",
      "        [[-0.2307, -1.7354, -0.4065,  0.3778,  0.9090, -0.1498],\n",
      "         [-0.5355, -1.2480, -0.0049,  0.1522,  0.5635, -0.0269],\n",
      "         [-0.4674, -0.8466,  0.0176,  0.1337,  0.4053, -0.2230],\n",
      "         [-0.3683, -0.6768,  0.0088,  0.0933,  0.3034, -0.3600],\n",
      "         [-0.2545, -0.5944, -0.0236,  0.0762,  0.3629, -0.3780]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 148
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
